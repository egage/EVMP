---
title: "Elk Vegetation Management Plan Analysis"
author: ""
date: ''
output:
  html_document: 
    theme: sandstone
    toc: yes
    toc_depth: 4
---

```{r setup, include=FALSE}
library(knitr)
opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE, fig.align = 'center')
opts_knit$set(root.dir=normalizePath('../')) # this is required if Rmd is nested below the project directory
opts_chunk$set(fig.path = "../output/figures/") # corrected path and added dev. Needed to specify a subdirectory for figs

# see discussion here: https://stackoverflow.com/questions/24585254/working-with-knitr-using-subdirectories

```


```{r, utilityFuncDefn, echo=FALSE, warning=FALSE,message=FALSE, comment=FALSE}
# define some utility functions...

#--------------------
# SO: http://stackoverflow.com/questions/11610377/how-do-i-change-the-formatting-of-numbers-on-an-axis-with-ggplot
# ...gives proper 'x10(superscript)5' notation on the axes. 

fancy_scientific <- function(l) {
     # turn in to character string in scientific notation
     l <- format(l, scientific = TRUE)
     # quote the part before the exponent to keep all the digits
     l <- gsub("^(.*)e", "'\\1'e", l)
     # turn the 'e+' into plotmath format
     l <- gsub("e", "%*%10^", l)
     # return this as an expression
     parse(text=l)
}

# Which you can then use as

# ggplot(data=df, aes(x=x, y=y)) +
#    geom_point() +
#    scale_y_continuous(labels=fancy_scientific) 


## fun to add r2
# GET EQUATION AND R-SQUARED AS STRING
# SOURCE: http://goo.gl/K4yh

lm_eqn <- function(df){
    m <- lm(y ~ x, df);
    eq <- substitute(italic(y) == a + b %.% italic(x)*","~~italic(r)^2~"="~r2, 
         list(a = format(coef(m)[1], digits = 2), 
              b = format(coef(m)[2], digits = 2), 
             r2 = format(summary(m)$r.squared, digits = 3)))
    as.character(as.expression(eq));                 
}

# p1 <- p + geom_text(x = 25, y = 300, label = lm_eqn(df), parse = TRUE)


########
## from https://www.r-bloggers.com/using-purrr-with-dplyr/
cut_equal_sizes <- function(x, n = 3, ...) {
  ggplot2::cut_number(x, n, ...)
}

cut_equal_ranges <- function(x, n = 10, ...) {
  cut(x, n, include.lowest = TRUE, ...)
}


# ######### DEAL WITH NA #############
# na_strings <- c("NA", "N A", "N / A", "N/A", "N/ A", "Not Available", "NOt available")
# 
# baseline <- baseline %>%
#   naniar::replace_with_na_all(condition = ~.x %in% na_strings) %>%

```

```{r, echo=FALSE, warning=FALSE,message=FALSE, comment=FALSE, eval=FALSE}

# some themes
theme_smFacet <- theme_bw() + theme(strip.text.x = element_text(size = 7))
theme_smFacet2 <- theme_bw() + theme(strip.text.x = element_text(size = 6))
theme_CowsMod1 <- theme_cowplot() + 
  theme(strip.text.x = element_text(size = 7)) +
  theme(plot.title = element_text(hjust = 0)) 

```


Author: E. Gage  

Contact: edgage@rams.colostate.edu

**PROVISIONAL DATA AND ANALYSES**

**Updated: `r format(Sys.time(), '%Y %B %d')`**

This is a working document aimed at facilitating data QA/QC and exploratory analysis. 
Please do not distribute.

# Introduction

```{r,echo=FALSE}
# library(here)
# here()
# install.packages("bindrcpp")
suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(fs))
suppressPackageStartupMessages(library(sf))
# library(raster)
suppressPackageStartupMessages(library(janitor))
suppressPackageStartupMessages(library(readxl))
# library(glue)
suppressPackageStartupMessages(library(mapview))
# library(ggmap)
# library(ggrepel)
suppressPackageStartupMessages(library(viridis))
# library(ggExtra)
suppressPackageStartupMessages(library(ggstance))
suppressPackageStartupMessages(library(readxl))
suppressPackageStartupMessages(library(DT))
# library(kableExtra)
suppressPackageStartupMessages(library(lubridate))
suppressPackageStartupMessages(library(skimr)) 
suppressPackageStartupMessages(library(dataMaid))
# library(ggmap)
library(lubridate)
library(mapview)

```

In 2008, Rocky Mountain National Park (RMNP) began implementation of the Elk and Vegetation Management Plan (EVMP), intended to guide management of elk and vegetation over a 20–yr period, reduce the impacts of elk on vegetation, and bring  of target ecosystems into the natural range of variability for elk and vegetation in three target vegetation communities: aspen, montane riparian willow, and upland. Using fencing, non-lethal redistribution and culling of elk herds, and active vegetation restoration, the plan incorporates the principle of adaptive management to guide management actions. Achieving the goals of the EVMP requires monitoring of target vegetation communities. 

RMNP and the U.S. Geological Survey (USGS) developed a vegetation monitoring program focused on EVMP goals. Monitoring sites were established and baseline data collected from 2006-2009 in core winter range aspen, willow, and upland communities. sites have been annually sampled  vegetation offtake by ungulates and various structural and compositional metrics have been montoeied on a five-year basis, with a second five-year-round of sampling completed in 2018. 

This document presents analyses of these data, evaluating datasets collected in willow, aspen, and upland herbaceous plots in core and non-core elk winter range sites on the east side of RMNP and the Kawunechee Valley. Data describing stem count, diameter, and shrub height over time are analyzed in relation to factors including study site location and whether plots were in fenced or unfenced areas. In addition, analyses evaluate effects of a 2012 wildfire that burned over Moraine Park, which provided a unique opportunity to study willow and aspen recovery after fire in both grazed and ungrazed conditions.

### Objectives 

This report analyzes data from the first 10 years of monitoring and will be used to assess progress towards the goals in the EVMP. Monitoring in the EVMP program is focused on assessing several community attributes (Zeigenfuss et al. 2011) including:

1.Vegetation offtake by herbivores in riparian shrub (primarily willow) and upland herbaceous communities, assessed through annual subsampling of sites  
2.Willow height and cover resampled every 5 years  
3.Aspen stem density and stem size distribution, assessed every 5 years through a full resampling of sites. 

The focus of the EVMP is the elk winter range. However, data are also collected in the Kawuneeche Valley, which is primarily summer range, to provide information on this important area of the park.


```{r, eval=FALSE}
# This document provides a basic exploration of EVMP files provided by RMNP in October of 2018.  The code and analyses aim to characterize basic data structure, identify problems, and clean and reorganize as needed for plotting and modeling. Specific objectives include identifying issues such as:
# 
# * Inconsistently named/typed factors    
# * Missing values
# * Data values outside of expected range or showing unusual patterns

# Cleaned and archivable data sets will be produced to facilitate future data analysis and aid RMNP in their management goals.

```



# Methods

## Vegetation Collection

Protocols detailed in the RMNP EVMP monitoring plan (Zeigenfuss et al. 2011) were used to collect vegetation data at study plots. A round of baseline measurements made from 2006–2009 were made (Zeigenfuss et al. 2011), with RMNP staff collecting subsequent data. A subsample of plots were visited annually beginning in 2007 for upland plots and 2009 willow plots and conducted through 2014 (Zeigenfuss et al. 2011). Offtake measures on willows were usually in May and June, but were delayed some to mid-July in some years due to weather. Other variables were assessed the year of plot establishment and during June through September in 2013and 2018.

## Data Exploration and Wrangling

Raw data files provided by RMNP in October 2018 were processed using functions in various data manipulation and visualizations packages in the R statistical package.  



Raw data were provided as 4 multi-tabbed Excel files:   

```{r}
# list of files, tidyverse approach: 
# file.listing <- dir_info(path = "./data/EVMP_data/TenYearReview", recurse = TRUE) %>%
#   filter(type == "file", permissions == "u+r", size > "10KB") %>%
#   arrange(desc(size)) %>%
#   View()
#   dplyr::select(path, size)

# datatable(file.listing, rownames = FALSE, caption = "List of files provided by RMNP 2018-10-10")


## base R approach
file.listing <- list.files(path = "./data/EVMP_data/TenYearReview") %>% 
  enframe() %>% 
  select(value) %>% 
  rename(fileName = value)

knitr::kable(file.listing, rownames = FALSE, row.names = FALSE, col.names = "file name")

```


```{r}
# xls_example <- readxl_example("datasets.xls")
# excel_sheets(xls_example)

# willow.off <- read_xlsx("data/EVMP_data/provisional_data_20180920/Willow Offtake Data 2009-2018.xlsx")
# read_excel(willow.off, sheet = "chickwts")
# excel_sheets(willow.off)
# 
# asp.bl <- read_excel("data/EVMP_data/provisional_data_20180920/Aspen_Baseline_2013_2018_5_Year_Msmts_Including_Burn_Data.xlsx") 
# 
# excel_sheets(asp.bl)

```


```{r, eval=FALSE}

# Create a cache of workbook tabs as CSV files

## cache csv. This creates a csv cache of each tab in the workbook.
read_then_csv <- function(sheet, path) {
  pathbase <- path %>%
    basename() %>%
    tools::file_path_sans_ext()
  path %>%
    read_excel(sheet = sheet) %>% 
    write_csv(paste0(pathbase, "-", sheet, ".csv"))
}

path %>%
  excel_sheets() %>%
  set_names() %>% 
  map(read_then_csv, path = path)
```



```{r}
##### READ IN CSV FILES FROM 
## list all the csv - as vector
# csv.all <- fs::dir_ls("data/EVMP_data/csv",glob = "*.csv")

## all the csv names and paths as tibble column
csv.all <- tibble(ffname = fs::dir_ls("data/EVMP_data/csv",glob = "*.csv"))

## list column approach. purrr to read csv into list column
csv.all.lc <- csv.all %>% 
  mutate(data = map(ffname,read_csv))

## 2 improve above: try specifying the NA string on import....

```


```{r}
#### maps
### The following code extracts out the most recent 'site info' file, creates a sf object for plotting and further spatial analysis. Note this is different than below where a different source spreadsheet provided by the park is evaluated. Here, its the info tab within the spreadsheet

# site info
sinfo <- csv.all.lc %>%
  filter(str_detect(ffname, "z2018 Site Info.csv"))

sinfo.df <- sinfo %>% 
  pluck(2) %>% 
  pluck(1)

```

```{r, site_info_01}

####### instead, lets look at the master 
# C:\Users\Ed\Git_repos\EVMP\data\EVMP_data\VEG_SITES_MSTR_DATABASE.xlsx

# data/EVMP_20181010/TenYearReview/Willow_Cumulative_Data_Baseline_Through_2018.xlsx
# si <- readxl::excel_sheets("data/EVMP_data/VEG_SITES_MSTR_DATABASE.xlsx")
# si

path.si <- ("data/EVMP_data/VEG_SITES_MSTR_DATABASE.xlsx")

#### Read in the worksheets and create list of df
# each tab is a df in the list object
si.d <- path.si %>% 
  excel_sheets() %>% 
  set_names() %>%
  map(read_excel, path = path.si) # 

## this retrieved ALL of the tabs. I'll subset the list to get to the desired tabs

site.info.willow <- si.d$'WILLOW SITES MASTER'
site.info.aspen <- si.d$'ASPEN SITES MASTER'
site.info.upland <- si.d$'UPLAND SITES MASTER'

# and the active master tab. 
site.info.active <- si.d$'ACTIVE VEG SITE LOCATION MASTER'

## gets the names of the individual sheets
# site.info.willow %>% names()
# site.info.aspen %>% names()
# site.info.upland %>% names()

## they don't have the same column names. The following vector is a subset in common
csel <- c("SITE_ID","UTM_E_NAD83","UTM_N_NAD83","FENCED","VALLEY","UTM_N_NAD83","BURNED")

site.info.willow <- select(site.info.willow,csel) %>% 
  mutate(pType = "willow")
site.info.aspen <- select(site.info.aspen,csel) %>% 
  mutate(pType = "aspen")
site.info.upland <- select(site.info.upland,csel) %>% 
  mutate(pType = "upland")

## combine
site.info.all <- rbind(site.info.willow, site.info.aspen,site.info.upland)


site.att <- site.info.active %>%
  dplyr::select(SITE_ID,RANGE_TYPE, WILDERNESS) 


# set NA and filter out columns lacking coordinates 
site.info.all <- site.info.all %>% 
  dplyr::na_if(.,"NA") %>%  # nice clean way of replacing all the text NA with real NA
  filter(!is.na(UTM_E_NAD83)) %>% # only keeping points with coordinates
  left_join(., site.att, by = "SITE_ID") # join by site id

### need to fill in this
# site.info.all %>% 
#   filter(is.na(RANGE_TYPE))

#### create SF from coordinates
site.info.all.sf <- site.info.all %>%
  mutate_at(2:3, as.numeric) %>% 
  st_as_sf(coords = c("UTM_E_NAD83", "UTM_N_NAD83"), crs = 26913)

# plot(site.info.all.sf)

```


```{r}
# site.info.all.sf %>% 
#   View()
#   names()
```


```{r}

site.info.all %>% 
  skimr::skim() %>% 
  kable(caption = "Basic information on 'site info' imported dataset.")

```


**Overview Map of EVMP sampling**


Change basemap or pan and zoom.

**Figure 1. Map of fenced and unfenced areas All plots**

```{r}
# mapviewOptions(basemaps = c("Esri.WorldShadedRelief"), # "Esri.WorldImagery"
#                vector.palette = colorRampPalette(c("snow", "cornflowerblue", "grey10")),
#                na.color = "magenta",
#                layers.control.pos = "topright")

site.info.all.sf %>%
  filter(!is.na(RANGE_TYPE)) %>%
  mapview(zcol='FENCED')

## write this to file and enter in Arc?

```

**Core winter range**



```{r}
# Note that "location" and "valley" exist in different workbooks/datasets, differ in attributes, and are incompletely attributed. 

site.info.all.sf %>% 
  filter(is.na(VALLEY)) %>%
  datatable(caption = "Records missing VALLEY attributes.")


```

> To do: attribute these.

**Burned plots map**

```{r}
site.info.all.sf %>%
  filter(!is.na(BURNED)) %>% 
  filter(BURNED != 'N') %>%
  filter(BURNED != 'Not burned') %>%
  mapview(zcol='BURNED')

# >What is "N Y"?  
# >How does "Y" compare to the other, more specific classes?
```




**Count of features by valley **

```{r}
### note this is still missing as na

site.info.all.sf %>%
  group_by(VALLEY) %>% 
  tally() %>% 
  # na.omit() %>%  ### NEED TO ATTRIBUTE THESE. BUT FOR TESTING....
  ggplot(aes(reorder(VALLEY, n),n)) +
  # ggplot( aes(VALLEY, n, size = n, color=VALLEY)) +
  geom_point(color="white", size = 6) +
  geom_pointrange(ymin=0, aes(ymax=n)) +
   geom_point(color="ivory3", size = 10) +
  geom_text(aes(label=n), size=6) +
  # scale_x_log10() +
  theme_minimal() +
  coord_flip() +
  labs(x="Count", y = "Valley", title = "Count of EVMP sampling sites")
  
# ggplotly(plotly1)
```



**Counts by "range type"**

```{r}

##
pl.cnt1 <- site.info.all.sf %>%
  group_by(VALLEY) %>% 
  tally() %>% 
  # na.omit() %>%  ### NEED TO ATTRIBUTE THESE. BUT FOR TESTING....
  ggplot(aes(reorder(VALLEY, n),n)) +
  # ggplot( aes(VALLEY, n, size = n, color=VALLEY)) +
  geom_point(color="white", size = 6) +
  geom_pointrange(ymin=0, aes(ymax=n)) +
   geom_point(color="ivory3", size = 10) +
  geom_text(aes(label=n), size=4) +
  # scale_x_log10() +
  theme_minimal() +
  labs(x="Valley", y = "Count", title = "Count of EVMP sampling sites") +
  coord_flip()

##

pl.cnt2 <- site.info.all.sf %>%
  group_by(RANGE_TYPE) %>% 
  tally() %>% 
  # na.omit() %>%  ### NEED TO ATTRIBUTE THESE. BUT FOR TESTING....
  ggplot(aes(reorder(RANGE_TYPE, n),n)) +
  # ggplot( aes(VALLEY, n, size = n, color=VALLEY)) +
  geom_point(color="white", size = 4) +
  geom_pointrange(ymin=0, aes(ymax=n)) +
   geom_point(color="ivory3", size = 10) +
  geom_text(aes(label=n), size=3) +
  # scale_x_log10() +
  theme_minimal() +
  # coord_flip() +
  theme(axis.text.x = element_text(angle = 30, hjust = 1)) +
  labs(x="Count", y = "Range type", title = "Count of EVMP sampling sites by 'Range type'")

pl.cnt2



pl.cnt1.cnt2 <- cowplot::plot_grid(pl.cnt1, pl.cnt2, labels = "AUTO")

# ggsave(plot = pl.cnt1.cnt2, filename = "./output/figures/twoPanel_valleyCnt_rangeCnt.png", width = 8, height = 5, dpi = 300)

## Note how many na! Need to fix




```


**Counts of fenced and unfenced**
```{r}


# site.info.all.sf %>%
#   group_by(FENCED,pType) %>% 
#   tally() %>% 
#   # na.omit() %>%  ### NEED TO ATTRIBUTE THESE. BUT FOR TESTING....
#   ggplot(aes(reorder(FENCED, n),n)) +
#   # ggplot( aes(VALLEY, n, size = n, color=VALLEY)) +
#   geom_point(color="white", size = 6) +
#   geom_pointrange(ymin=0, aes(ymax=n)) +
#    geom_point(color="ivory3", size = 10) +
#   geom_text(aes(label=n), size=6) +
#   # scale_x_log10() +
#   theme_bw() +
#   # theme_minimal() +
#   coord_flip() +
#   labs(x="Count", y = "Range type", title = "Count of EVMP sampling sites by 'Range type'") +
#   facet_wrap(~pType)


pl.hm1 <- site.info.all.sf %>%
  group_by(FENCED,VALLEY) %>% 
  tally() %>% 
  # na.omit() %>%  ### NEED TO ATTRIBUTE THESE. BUT FOR TESTING....
  ggplot(aes(FENCED, VALLEY)) +
  geom_tile(aes(fill = n), color= 'white') +
  # geom_point(color="white", size = 6) +
  geom_text(aes(label=n), size=8, color = 'white') +
  # scale_x_log10() +
  # theme_bw() +
  theme_minimal() +
  # scale_fill_gradient(low = "ivory4",high = "black") +
  scale_fill_viridis() +
  # theme_minimal() +
  # coord_flip() +
  labs(x="Fenced", y = "Range type", title = "Count of EVMP sampling sites",subtitle = "By 'Range type' and and fenced status")


pl.hm2 <- site.info.all.sf %>%
  group_by(FENCED,pType) %>% 
  tally() %>% 
  # na.omit() %>%  ### NEED TO ATTRIBUTE THESE. BUT FOR TESTING....
  ggplot(aes(FENCED, pType)) +
  geom_tile(aes(fill = n), color= 'white') +
  # geom_point(color="white", size = 6) +
  geom_text(aes(label=n), size=8, color = 'white') +
  # scale_x_log10() +
  # theme_bw() +
  theme_minimal() +
  scale_fill_gradient(low = "ivory4",high = "black") +
  # theme_minimal() +
  # coord_flip() +
  labs(x="Fenced", y = "", title = "Count of EVMP sampling sites", subtitle = "By plot type and fenced status")

cowplot::plot_grid(pl.hm1, pl.hm2, labels = "AUTO", ncol=2)

```



```{r}
#### Cleaning
# data.entry(site.info.all)

```



**Individual Site Maps**
```{r, eval = FALSE}
## scrap: creat functions to create basemaps with ggplot
library(ggmap)  # you may have to use install.packages to install it first
b <- ggmap::bbox(lnd)
(lnd.b1 <- ggmap(get_map(location = b)))  # download map data for the lnd data and plot

ggmap::bb2bbox()

```


```{r}
## nested by range type 

site.info.all.sf.nest <- site.info.all.sf %>% 
  filter(!is.na(RANGE_TYPE)) %>% 
  group_by(RANGE_TYPE) %>% 
  nest()

```


```{r, eval=TRUE}
##ggmap site maps. Need base maps

site.info.all.sf.nest <- site.info.all.sf.nest %>% 
  mutate(plot = map2(data,RANGE_TYPE, ~ggplot(data = .x) + theme_bw() +
                       geom_sf() +
                       labs(title = .y))) 
# library(OpenStreetMap)

```

```{r, eval = FALSE}
## pring the ggmaps
mm1 <- site.info.all.sf.nest %>% 
  pluck(3) %>% pluck(1) 
mm1

mm2 <- site.info.all.sf.nest %>% 
  pluck(3) %>% pluck(2)
mm2

mm3 <- site.info.all.sf.nest %>% 
  pluck(3) %>% pluck(3)
mm3

# cowplot::plot_grid(mm1,mm2,mm3,nrow = 1)
# file_names <- paste0(country_list, ".pdf")
# map2(paste0(plots$country, ".pdf"), plots$plot, ggsave)  

# ### 
# sinfo.sf %>% 
#   group_by(SITE_TYPE) %>% 
#   nest() %>% 
#   walk2(.x = data,.f = mapview)
#   mutate(plot2 = map(.$SITE_TYPE, mapview)) 
```


```{r}

site.info.all.sf.nest <- site.info.all.sf.nest %>% 
  mutate(plot2_MV = map(data,mapview)) 

### this prints them all out.
# site.info.all.sf.nest %>%
#   pluck(4)
## seemingly just to console, not when knit for mapview
## BUT it does work for ggplot objects...
# site.info.all.sf.nest %>%
#   pluck(3)

```


##
### East-side Core Winter Range (WC) Map

```{r, fig.align='center'}

## map: Core Winter Range
site.info.all.sf.nest %>% 
  pluck(2) %>% pluck(1) %>% 
  # names()
  mapview(zcol = "FENCED")

```

### East-side Non-core Winter Range (WC) Map
```{r, fig.align='center'}

## map: KV
site.info.all.sf.nest %>% 
  pluck(2) %>% pluck(3) %>% 
  mapview(zcol = "FENCED")

```


### West-side Kawuneeche Valley (WK) Map
```{r, fig.align='center'}

## map: KV
site.info.all.sf.nest %>% 
  pluck(2) %>% pluck(2) %>% 
  mapview(zcol="FENCED")

# site.info.all.sf.nest %>% 
#   pluck(2) %>% 
#   pluck(2) %>%
#   ggplot() +
#   geom_sf(aes(color = FENCED)) +
#   theme_minimal()

```

### Willow QA/QC {.tabset}


```{r}
#### There are to duplicate sets of files, one with a 'z' in the name, one without, but otherwise seeming the same. In this chunk, picking one set (the zed set)

csv.all.lc <- csv.all.lc %>% 
  filter(str_detect(ffname, "z")) 

```

```{r}
######### CREATE TYPE FIELD #########
## this will make parsing variables in into groups easier  

csv.all.lc <- csv.all.lc %>% 
  mutate(file_name_abr = str_replace(string = ffname, pattern = "data/EVMP_data/csv/Willow_Cumulative_Data_Baseline_Through", replacement = "F"))

## case when into type
csv.all.lc <- csv.all.lc %>% 
  dplyr::select(-ffname) %>%
  mutate(vType = case_when(grepl("Macro", file_name_abr) ~ "Macroplot",
                          grepl("site", file_name_abr, ignore.case = TRUE) ~ "Site_info",
                          grepl("Key", file_name_abr, ignore.case = TRUE) ~ "Key",
                          grepl("Line", file_name_abr, ignore.case = TRUE) ~ "Line_int"
                          )
         )

```


```{r}
## Variable names across input files 
# extract the field names from each csv
csv.all.lc <- csv.all.lc %>% 
  mutate(field_names = map(data, names)) 
  
# unnest to get at field names
# across all csv files
csv.all.lc %>% 
  unnest(field_names) %>% 
  distinct(file_name_abr,field_names) %>% 
  datatable(rownames = FALSE, caption = "Distinct field names acrosss all csv files")

#### Distinct field names via unnest()
# csv.all.lc %>% 
#   unnest(field_names) %>% 
#   distinct(ffname,field_names) %>% 
#   datatable()

```


#### Line intercept Analysis

>Distinct variable names across all input csv files for just line intercept plot

```{r}
## just line intercept
csv.all.lc.li <- csv.all.lc %>% 
  filter(vType == "Line_int") 

csv.all.lc.li %>% 
  unnest(field_names) %>% 
  distinct(file_name_abr,field_names) %>% 
  # write_csv("output/temp_4_review/distinc_line_in_names.csv")
  datatable(rownames = FALSE, caption = "Distinct variable names for line intercept files.")

```


```{r}
#### FUNCTIONS 
#### Select multiple columns. Note some key interecept ones don't work!
# need to figure out  

filtFunSel <- function(x){
  x %>% dplyr::select(c(DATE,
                      SITE_TYPE,
                      SITE_NUMBER,
                      SITE_ID,
                      SPECIES_CODE,
                      #SHRUB_INTERCEPT_START_M,
                      #SHRUB_INTERCEPT_STOP_M,
                      MAX_HEIGHT_CM,
                      #DEAD,
                      BROWSED,
                      INTERCEPT_LENGTH_M,
                      GENUS))
}

# now create new list column with the selected rows as specfied in the function
csv.all.lc.li <- csv.all.lc.li %>% 
  mutate(data.sel = map(.x = data, filtFunSel))

# csv.all.lc.li %>% 
#   unnest(field_names) %>% 
#   distinct(field_names)%>% 
#   datapasta::dpasta()

## purrr ninja move:
csv.all.lc.li.df <- csv.all.lc.li %>% 
  pluck(1) %>%
  map(filtFunSel) %>% 
  reduce(.f = rbind)
# yay, pluck()!

```

```{r}
##
csv.all.lc.li.df <- csv.all.lc.li.df %>%
  mutate(DATE = as.Date(DATE)) %>% 
  mutate(yr = as.factor(year(DATE))) %>%
  mutate(mo = month(DATE))

# csv.all.lc.li.df %>% 
#   filter(!is.na(MAX_HEIGHT_CM)) %>%
#   # names() %>% 
#   group_by(yr,SITE_TYPE, SITE_NUMBER, SITE_ID, MAX_HEIGHT_CM) %>% 
#   summarize()
  

```


```{r}

## Create a spatial lookup table for joining site info.
sp.lu <- sinfo.df %>%
  dplyr::select(-c(SITE_TYPE,DATE,SITE_NUMBER, GPS_ACCURACY_M))

csv.all.lc.li.df <- left_join(csv.all.lc.li.df, sp.lu, by= "SITE_ID")

```

```{r}

csv.all.lc.li.df %>% 
  skimr::skim() %>% 
  kable(caption = "Basic information on 'line intercept' imported dataset.")


```



```{r, eval=FALSE, echo=FALSE}

#  NOT run. Workin in progress

csv.all.lc.li.df %>% 
  filter(yr == 2013 | yr == 2018) %>% 
  mutate(yr = as.double(yr)) %>%
  ggplot(aes(yr, MAX_HEIGHT_CM)) +
  geom_point() +
  geom_line(color="black", aes(x=yr, y = MAX_HEIGHT_CM))

## filter to 2013 and 2018
csv.all.lc.li.df %>% 
  filter(yr == 2013 | yr == 2018) %>%
  # group_by(SITE_ID,SPECIES_CODE,DATE) %>% 
  group_by(SITE_ID,SPECIES_CODE,yr) %>% 
  summarise(mean.max = mean(MAX_HEIGHT_CM, na.rm=TRUE), sd.max = sd(MAX_HEIGHT_CM, na.rm=TRUE), n.max = n()) %>% 
  filter(SPECIES_CODE == "SAMO") %>% 
  ungroup() %>%
  filter(n.max >1) %>% 
  ggplot(aes(yr,mean.max)) +
  geom_point() +
  geom_line(aes(x=yr, y = mean.max))
  
# tidyr::spread(key = yr, value = MAX_HEIGHT_CM, convert = FALSE)


```



#### Macroplot Inventory Analysis


```{r}
csv.all.lc.mcro <- csv.all.lc %>% 
  filter(vType == "Macroplot") 

#
csv.all.lc.mcro %>% 
  unnest(field_names) %>% 
  distinct(file_name_abr,field_names) %>% 
  # write_csv("output/temp_4_review/macroplot_fld_names.csv")
  datatable(rownames = FALSE, caption = "Macroplot inventory variable names.")

```

```{r, eval=FALSE}
csv.all.lc.mcro %>% 
  unnest(field_names) %>% 
  # tabyl(file_name_abr)
  tabyl(file_name_abr,field_names) %>% 
  # write_csv("output/temp_4_review/macroplot_fld_names.csv")
  datatable(rownames = FALSE, caption = "Macroplot inventory variable names.")

```


```{r}

FunSelMacro <- function(x){
  x %>% dplyr::select(c(DATE,
                      SITE_TYPE,
                      SITE_NUMBER,
                      SITE_ID,
                      SPECIES_CODE,
                      PERCENT_PLANT_IN_PLOT,
                      CANOPY_DIA_1_CM,
                      CANOPY_DIA_2_CM,
                      PLANT_HT_CM,
                      HT_TO_TALLEST_BUDSCAR_CM))
}


csv.all.lc.mcro <- csv.all.lc.mcro %>% 
  mutate(data.sel = map(.x = data, FunSelMacro))

# csv.all.lc.li %>% 
#   unnest(field_names) %>% 
#   distinct(field_names)%>% 
#   datapasta::dpasta()


## badass purrr ninja move:
csv.all.lc.mcro.df <- csv.all.lc.mcro %>% 
  pluck(1) %>%
  map(FunSelMacro) %>% 
  reduce(.f = rbind)

```

```{r}
csv.all.lc.mcro.df <- csv.all.lc.mcro.df %>% 
  mutate(yr = year(DATE)) %>% 
  mutate(mo = lubridate::month(DATE))
```

```{r}

### join in the spatial/site info
csv.all.lc.mcro.df <- left_join(csv.all.lc.mcro.df, sp.lu, by = "SITE_ID")

```


### Data cleaning {.tabset .tabset-fade .tabset-pills}

The following plots are used to assess patterns of "missingness" in data sets. 

_Click on tabs to view different plots._


```{r, eval=FALSE}
#### Missing observations across variables and years
naniar::vis_miss(csv.all.lc.li.df)

```


#### Missingness across years 

```{r}

mplot1 <- csv.all.lc.li.df %>% 
  mutate(yr = year(DATE)) %>% 
  mutate(yr = as.factor(yr)) %>% 
  naniar::gg_miss_fct(yr) +
  theme_minimal() + 
  labs(title = 'Missing data', y = "", x="Year", fill = "% missing")

mplot1

```

```{r, eval=FALSE}

csv.all.lc.li.df %>% 
  group_by(yr) %>% 
  nest() %>% 
  map(data, naniar::vis_miss)

naniar::vis_miss(csv.all.lc.li.df) %>% 
  facet_wrap(~)
```

#### Missingness across months 

```{r}
csv.all.lc.li.df %>% 
  mutate(mo = month(DATE)) %>% 
  naniar::gg_miss_fct(mo) +
  labs(title = "Variables: Missing data by month", x="Month") +
  scale_fill_viridis(discrete = FALSE, option = "A")

```


### Upland QA/QC

```{r}


# ######### DEAL WITH NA #############
# na_strings <- c("NA", "N A", "N / A", "N/A", "N/ A", "Not Available", "NOt available")
# 
# baseline <- baseline %>%
#   naniar::replace_with_na_all(condition = ~.x %in% na_strings) %>%



```



### Upland Line Intercept 2007-2018

Upland line intercept transect data were collected in core upland (UC) and upland noncore areas (UNC) along a 30m transect line. Observations included the presence of tracks, scat, burrows, plant damage, or browse. In addition, observation of animal sign were made for elk, deer, moose, ground squirrells, tent catippilars, big horn sheep, and raptors.




```{r, eval=FALSE}
csv.all.lc.asp <- csv.all.lc %>% 
  filter(vType == "Macroplot") 

#
csv.all.lc.asp %>% 
  unnest(field_names) %>% 
  distinct(file_name_abr,field_names) %>% 
  # write_csv("output/temp_4_review/macroplot_fld_names.csv")
  datatable(rownames = FALSE, caption = "Macroplot inventory variable names.")


csv.all.lc.asp %>% 
  unnest(field_names) %>% 
  # tabyl(file_name_abr)
  tabyl(file_name_abr,field_names) %>% 
  # write_csv("output/temp_4_review/macroplot_fld_names.csv")
  datatable(rownames = FALSE, caption = "Macroplot inventory variable names.")


```


```{r, eval=FALSE}

FunSelAsp <- function(x){
  x %>% dplyr::select(c(DATE,
                      SITE_TYPE,
                      SITE_NUMBER,
                      SITE_ID,
                      SPECIES_CODE,
                      PERCENT_PLANT_IN_PLOT,
                      CANOPY_DIA_1_CM,
                      CANOPY_DIA_2_CM,
                      PLANT_HT_CM,
                      HT_TO_TALLEST_BUDSCAR_CM))
}

csv.all.lc.asp <- csv.all.lc.mcro %>% 
  mutate(data.sel = map(.x = data, FunSelMacro))

# csv.all.lc.li %>% 
#   unnest(field_names) %>% 
#   distinct(field_names)%>% 
#   datapasta::dpasta()


## combine all using purrr, ninja-style:
csv.all.lc.asp.df <- csv.all.lc.asp %>% 
  pluck(1) %>%
  map(FunSelAsp) %>% 
  reduce(.f = rbind)

```

```{r}

csv.all.lc.mcro.df <- csv.all.lc.mcro.df %>% 
  mutate(yr = year(DATE)) %>% 
  mutate(mo = lubridate::month(DATE))

```

### Statistical analyses




# Results 

## Willow

### Shrub height

**Max shrub height: Core winter range**

```{r}
#Shrub Line Intercept Datataset 
csv.all.lc.li.df %>% 
  filter(!is.na(FENCED)) %>% 
  filter(!is.na(MAX_HEIGHT_CM)) %>%
  # group_by(yr,SITE_TYPE, FENCED, SITE_ID, SPECIES_CODE) %>%
  filter(SITE_TYPE == "WC") %>% 
  group_by(yr,SITE_TYPE, FENCED, SPECIES_CODE) %>%
  summarise(mean.max.ht = mean(MAX_HEIGHT_CM, na.rm=TRUE)) %>% 
  filter(FENCED != "Y_but_fence_down_since_2013") %>% 
  ggplot(aes(yr, SPECIES_CODE)) +
  geom_tile(aes(fill=mean.max.ht),color = 'white') +
  scale_fill_viridis(option = "A") +
  theme_bw() +
  labs(title = "Maximum shrub height", subtitle = "Mean of shrub height pooled by fenced status", x = "Year", y = "Species", fill = "") +
  facet_wrap(~FENCED, ncol= 2)

ggsave("./output/figures/maxShrubHy_by_spp_WC_heatmap.png", width = 6.5, height = 6.5, dpi = 300)

```

```{r, echo=FALSE}

## theres a problem with the spatial join. MAny records without attributes like "FENCED"
# csv.all.lc.li.df %>% 
#   filter(is.na(LOCATION)) %>% 
#   View()

## core winter range
csv.all.lc.li.df %>% 
  filter(!is.na(MAX_HEIGHT_CM)) %>%
  # group_by(yr,SITE_TYPE, FENCED, SITE_ID, SPECIES_CODE) %>%
  filter(SITE_TYPE == "WC") %>% 
  filter(yr == 2008 | yr == 2013 | yr == 2018) %>% 
  filter(str_detect(SPECIES_CODE, "^SA")) %>%
  filter(SPECIES_CODE !="SAPE" & SPECIES_CODE !="SAWO" & SPECIES_CODE !="SAXX" & SPECIES_CODE !="SALUC" & SPECIES_CODE !="SABR"& SPECIES_CODE !="SAER") %>% 
  ggplot(aes(yr,MAX_HEIGHT_CM)) +
  geom_boxplot(aes(fill = FENCED)) +
  # scale_fill_viridis(option = "A") +
    theme_bw() +
  labs(title = "Maximum shrub height", x = "Year", y = "Max shrub height (cm)") +
  facet_grid(LOCATION~SPECIES_CODE)
  # facet_wrap(~SPECIES_CODE, ncol= 5)

```

>Need to determine how to properly deal with "NA" and "Y_but_fence_down_since_2013" in "FENCED" field.

#### All shrub species and years by type

```{r}
csv.all.lc.li.df %>% 
  filter(!is.na(MAX_HEIGHT_CM)) %>%
  # names() %>% 
  group_by(yr,SITE_TYPE, SPECIES_CODE, MAX_HEIGHT_CM) %>%
  summarise(mean.max.ht = mean(MAX_HEIGHT_CM,na.rm=TRUE)) %>% 
  ggplot(aes(yr, SPECIES_CODE)) +
  geom_tile(aes(fill=MAX_HEIGHT_CM),color = 'white') +
  scale_fill_viridis(option = "C") +
  # theme_minimal() +
  theme_bw() +
  labs(title = "Maximum shrub height", x = "Year", y = "Species") +
  facet_wrap(~SITE_TYPE, ncol = 3) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))


```


SITE_TYPE: WC=Willow Core, WNC=Willow Noncore, WK=Willow Kawuneeche Valley

```{r}
csv.all.lc.li.df %>% 
  filter(!is.na(MAX_HEIGHT_CM)) %>%
  filter(str_detect(SPECIES_CODE, "^SA")) %>% 
  filter(SPECIES_CODE !="SAPE" & SPECIES_CODE !="SAWO" & SPECIES_CODE !="SAXX" & SPECIES_CODE !="SALUC" & SPECIES_CODE !="SABR"& SPECIES_CODE !="SAER") %>%
  # names() %>% 
  # group_by(yr,SITE_TYPE, SPECIES_CODE, MAX_HEIGHT_CM) %>%
  # summarise(mean.max.ht = mean(MAX_HEIGHT_CM,na.rm=TRUE)) %>% 
  ggplot(aes(yr, MAX_HEIGHT_CM)) +
  geom_boxplot(aes(fill=SITE_TYPE), color = 'black') +
  scale_fill_viridis(discrete = TRUE) +
  theme_minimal() +
  labs(title = "Maximum shrub height", x = "Year", y = "Species", subtitle = "Pooled data evaluated for the most commonly encounted willow spp. across transects") +
  # facet_wrap(~SPECIES_CODE, ncol = 5) +
  facet_grid(SITE_TYPE~SPECIES_CODE) +
  theme(axis.text.x=element_text(angle=45,hjust=1))
  # facet_grid(SPECIES_CODE~yr)


```

### Willow height: _Salix monitcola_ 
```{r}

## Panel plot: Willow species
csv.all.lc.li.df %>%
  filter(yr !=2009 & yr != 2015 & yr !=2017) %>% 
  filter(SPECIES_CODE == "SAMO") %>%   filter(!is.na(MAX_HEIGHT_CM)) %>%
  filter(str_detect(SPECIES_CODE, "^SA")) %>% 
  filter(SPECIES_CODE !="SAPE" & SPECIES_CODE !="SAWO" & SPECIES_CODE !="SAXX" & SPECIES_CODE !="SALUC" & SPECIES_CODE !="SABR"& SPECIES_CODE !="SAER") %>%
  filter(str_detect(SPECIES_CODE, "^SA")) %>%
  ggplot() +
  ggridges::geom_density_ridges(aes(x = MAX_HEIGHT_CM, y =  yr, fill = SITE_TYPE), alpha = 0.45, ) +
  viridis::scale_fill_viridis(discrete = TRUE, option = "D") +
  theme_minimal() +
  facet_wrap(~SITE_TYPE, ncol = 1) +
  labs(x = "Max height (cm)", y = "Year", caption = "Salix monticola")
  
  # names() %>% 
  # group_by(yr,SITE_TYPE, SPECIES_CODE, MAX_HEIGHT_CM) %>%
  # summarise(mean.max.ht = mean(MAX_HEIGHT_CM,na.rm=TRUE))

```


```{r, fig.height=9, fig.width=8}
### Max shrub height

csv.all.lc.li.df %>% 
  filter(!is.na(MAX_HEIGHT_CM)) %>%
  filter(str_detect(SPECIES_CODE, "^SA")) %>% 
  filter(SPECIES_CODE !="SAPE" & SPECIES_CODE !="SAWO" & SPECIES_CODE !="SAXX" & SPECIES_CODE !="SALUC" & SPECIES_CODE !="SABR" & SPECIES_CODE !="SAER") %>%
  # names() %>% 
  # group_by(yr,SITE_TYPE, SPECIES_CODE, MAX_HEIGHT_CM) %>%
  # summarise(mean.max.ht = mean(MAX_HEIGHT_CM,na.rm=TRUE)) %>% 
  ggplot(aes(yr, MAX_HEIGHT_CM)) +
  geom_boxplot(aes(fill=SITE_TYPE), color = 'black') +
  scale_fill_viridis(discrete = TRUE) +
  # theme_minimal() +
  theme_bw() +
  labs(title = "Maximum shrub height by year, species and Site Type", x = "Year", y = "Species")+
  facet_wrap(~SPECIES_CODE, ncol = 3)# %>%
  # facet_grid(SPECIES_CODE~yr, scales = "free_x")

```



```{r}

csv.all.lc.li.df %>% 
  filter(yr != "2015" & yr != "2009" & yr != "") %>% 
  filter(!is.na(MAX_HEIGHT_CM)) %>%
  filter(str_detect(SPECIES_CODE, "^SA")) %>% 
  filter(SPECIES_CODE !="SAPE" & SPECIES_CODE !="SAWO" & SPECIES_CODE !="SAXX" & SPECIES_CODE !="SALUC" & SPECIES_CODE !="SABR" & SPECIES_CODE !="SAER") %>%
  filter(SITE_TYPE == "WC") %>% 
  ggplot(aes(yr, MAX_HEIGHT_CM)) +
  geom_boxplot(aes(fill=FENCED), color = 'black') +
  # scale_fill_viridis(discrete = TRUE) +
  # theme_minimal() +
  theme_bw() +
  labs(title = "Maximum shrub height by year, species and fencing", x = "Year", y = "Species")+
  # facet_wrap(~SPECIES_CODE, ncol = 3) %>%
  facet_grid(SPECIES_CODE~yr, scales = "free_x")

```

> Make assumption that "NA" for fenced is not fenced?

### Core winter range: fenced vs unfenced
```{r}
## will want to be sure interannual comparisons are made on using the right sets of points
## if, for example, 1/3 of 2018 plots were sampled in 2017, a comparison made on all of the 2018 data wouldn't make too much sense. 


# SAMO        
# SAPL        
# SAGE        
# SABE        
# SADR
##
csv.all.lc.li.df %>% 
  filter(!is.na(MAX_HEIGHT_CM)) %>%
  filter(str_detect(SPECIES_CODE, "^SA")) %>% 
  filter(FENCED == "N" | FENCED == "Y") %>% 
  filter(SPECIES_CODE !="SAPE" & SPECIES_CODE !="SAWO" & SPECIES_CODE !="SAXX" & SPECIES_CODE !="SALUC" & SPECIES_CODE !="SABR" & SPECIES_CODE !="SAER") %>%
  filter(SITE_TYPE == "WC") %>% 
  ggplot(aes(yr, MAX_HEIGHT_CM)) +
  geom_boxplot(aes(fill=FENCED), color = 'black') +
  scale_fill_viridis(discrete = TRUE) +
  # theme_minimal() +
  theme_minimal() +
  scale_fill_manual(values = c("ivory2","lightblue")) +
  labs(x = "Year", y = "Max height (cm)", fill = "Fenced?", caption = "All plots and Salix species")
  # labs(title = "Salix monticola maximum shrub height by year, fencing", x = "Year", y = "Species")




```

```{r}

csv.all.lc.li.df %>% 
  filter(!is.na(MAX_HEIGHT_CM)) %>%
  filter(str_detect(SPECIES_CODE, "^SA")) %>% 
  filter(FENCED == "N" | FENCED == "Y") %>% 
  filter(SPECIES_CODE !="SAPE" & SPECIES_CODE !="SAWO" & SPECIES_CODE !="SAXX" & SPECIES_CODE !="SALUC" & SPECIES_CODE !="SABR" & SPECIES_CODE !="SAER") %>%
  # distinct(SPECIES_CODE)
  filter(SITE_TYPE == "WC") %>% 
  ggplot(aes(yr, MAX_HEIGHT_CM)) +
  geom_boxplot(aes(fill=FENCED), color = 'black') +
  scale_fill_viridis(discrete = TRUE) +
  # theme_minimal() +
  theme_minimal() +
  scale_fill_manual(values = c("ivory2","lightblue")) +
  labs(x = "Year", y = "Max height (cm)", fill = "Fenced?")
  # labs(title = "Salix monticola maximum shrub height by year, fencing", x = "Year", y = "Species")



```

```{r}

```

Maximum Core winter range sites, maximum shrub height by species, fencing treatment, and year in line interecept dataset.**
```{r}

csv.all.lc.li.df %>% 
  filter(!is.na(MAX_HEIGHT_CM)) %>%
  filter(str_detect(SPECIES_CODE, "^SA")) %>% 
  filter(FENCED == "N" | FENCED == "Y") %>% 
  # filter(SPECIES_CODE !="SAPE" & SPECIES_CODE !="SAWO" & SPECIES_CODE !="SAXX" & SPECIES_CODE !="SALUC" & SPECIES_CODE !="SABR" & SPECIES_CODE !="SAER") %>%
  filter(SITE_TYPE == "WC") %>% 
  group_by(SPECIES_CODE,yr,FENCED) %>% 
  # View()
  dplyr::summarise(mean.max.ht = mean(MAX_HEIGHT_CM, na.rm = TRUE)) %>%
  ungroup() %>% 
  mutate(yr = as.character(yr)) %>% 
  mutate(yr = anytime::anytime(yr)) %>% 
  # mutate(yr = as.integer(yr)) %>% 
  ggplot(aes(x = yr, y = mean.max.ht)) +
  # geom_line(aes(color = FENCED)) +
  geom_smooth(aes(color = FENCED), method = "lm", se = FALSE, alpha = .5) +
  geom_point(aes(color = FENCED)) +
  # geom_boxplot(aes(fill=FENCED), color = 'black') +
  # scale_fill_viridis(discrete = TRUE) +
  # theme_minimal() +
  theme_bw() +
  # scale_fill_manual(values = c("ivory2","lightblue")) +
  labs(title = "Core winter range sites: maximum shrub height by year, fencing", x = "Year", y = "Height  (cm)") +
  facet_wrap(~SPECIES_CODE, ncol = 2)
  

```

**Core winter range sites, maximum shrub height by species, fencing treatment, and year in line interecept dataset.** 

```{r}
csv.all.lc.li.df %>% 
  filter(!is.na(MAX_HEIGHT_CM)) %>%
  # filter(str_detect(SPECIES_CODE, "^SA")) %>% 
  filter(FENCED == "N" | FENCED == "Y") %>% 
  filter(SPECIES_CODE !="SAPE" & SPECIES_CODE !="SAWO" & SPECIES_CODE !="SAXX" & SPECIES_CODE !="SALUC" & SPECIES_CODE !="SABR" & SPECIES_CODE !="SAER" | SPECIES_CODE !="ACGL" | SPECIES_CODE !="RUID") %>%
  # filter(SITE_TYPE == "WC") %>% 
  group_by(yr,FENCED, SPECIES_CODE) %>% 
  dplyr::summarise(mean.max.ht = mean(MAX_HEIGHT_CM, na.rm = TRUE), sd.max.ht = sd(MAX_HEIGHT_CM, na.rm=TRUE)) %>%
  ungroup() %>% 
  group_by(SPECIES_CODE) %>% 
  mutate(n.sp = n()) %>% 
  filter(n.sp > 5) %>% 
  ungroup() %>% 
  mutate(yr = as.character(yr)) %>% 
  mutate(yr = anytime::anytime(yr)) %>% 
  # mutate(yr = as.integer(yr)) %>% 
  ggplot(aes(x = yr, y = mean.max.ht)) +
  # geom_line(aes(color = FENCED)) +
  geom_smooth(aes(color = FENCED), method = "lm", se = FALSE) +
  geom_errorbar(aes(ymin = mean.max.ht - sd.max.ht, ymax = mean.max.ht + sd.max.ht, color = FENCED)) +
  geom_point(aes(color = FENCED),position="dodge") +
  # geom_boxplot(aes(fill=FENCED), color = 'black') +
  # scale_fill_viridis(discrete = TRUE) +
  # theme_minimal() +
  theme_bw() +
  labs(title = "Core winter range sites: maximum shrub height by year, fencing", x = "Year", y = "Height (cm)", subtitle = "Error bars represent +/- 1 SD, Trend line is a LM fit. Note scale of y axis varies between panels.") +
  facet_wrap(~SPECIES_CODE, ncol = 2, scales= 'free')

```


```{r}



csv.all.lc.li.df %>% 
  filter(!is.na(MAX_HEIGHT_CM)) %>%
  filter(str_detect(SPECIES_CODE, "^SA")) %>%
  filter(FENCED == "N" | FENCED == "Y") %>% 
  # filter(SPECIES_CODE !="SAPE" & SPECIES_CODE !="SAWO" & SPECIES_CODE !="SAXX" & SPECIES_CODE !="SALUC" & SPECIES_CODE !="SABR" & SPECIES_CODE !="SAER") %>%
  filter(SITE_TYPE == "WC") %>% 
  mutate(yr = as.character(yr)) %>% 
  mutate(yr = anytime::anytime(yr)) %>% 
  # mutate(yr = as.integer(yr)) %>% 
  ggplot(aes(x = yr, y = MAX_HEIGHT_CM)) +
  # geom_line(aes(color = FENCED)) +
  geom_smooth(aes(color = FENCED), method = "lm", se = FALSE) +
  geom_point(aes(color = FENCED)) +
  # geom_boxplot(aes(fill=FENCED), color = 'black') +
  # scale_fill_viridis(discrete = TRUE) +
  # theme_minimal() +
  theme_bw() +
  # scale_fill_manual(values = c("ivory2","lightblue")) +
  labs(title = "Core winter range sites: maximum shrub height by year, fencing", x = "Year", y = "Height (cm)", subtitle = "All willow species combined.") 


```


```{r}
## regression


```


FENCED: (Y=Yes, N=No, P=Planned)

BROWSED: (Y=Yes, N=No)

----

```{r, eval=FALSE}

# csv.all.lc %>% View()

# unnest to get at field names
# across all csv files
csv.all.lc %>% 
  unnest(field_names) %>% 
  distinct(ffname,field_names) %>% 
  datatable()


```




```{r}

csv.all.lc.mcro %>% 
  unnest(field_names) %>% 
  distinct(file_name_abr,field_names) %>% 
  # write_csv("output/temp_4_review/macroplot_fld_names.csv")
  datatable(rownames = FALSE, caption = "Macroplot inventory variable names.")


```

### Canopy Diameter


Canopy diameter measurements from macroplots. Calculated as the mean of CANOPY_DIA_1_CM + CANOPY_DIA_2_CM. 

```{r, eval=TRUE}
## average the canopy
csv.all.lc.mcro.df <- csv.all.lc.mcro.df %>% 
  # names() %>% 
  mutate(CANOPY_DIA_CM_avg = (CANOPY_DIA_1_CM + CANOPY_DIA_2_CM)/2)

# csv.all.lc.mcro.df %>% 
#   head()

```


**Summary table of canopy diameter by species **
```{r, eval=FALSE}

# skimr
# skimr::skim(iris, Sepal.Length, Petal.Length)

csv.all.lc.mcro.df %>% 
  group_by(yr,SPECIES_CODE) %>% 
  skimr::skim(CANOPY_DIA_CM_avg) %>% 
  kable()

```


```{r, eval=FALSE}

csv.all.lc.mcro.df %>%
  # filter(yr == "2009" | yr == "2013") %>% 
    filter(str_detect(SPECIES_CODE, "^SA")) %>% 
  filter(SPECIES_CODE !="SAPE" & SPECIES_CODE !="SAWO" & SPECIES_CODE !="SAXX" & SPECIES_CODE !="SALUC" & SPECIES_CODE !="SABR" & SPECIES_CODE !="SAER") %>% 
  mutate(yr = as.factor(yr)) %>% 
  ggplot(aes(yr, CANOPY_DIA_CM_avg)) +
  geom_jitter() +
  facet_grid(SPECIES_CODE~SITE_TYPE) +
  theme_bw()

```

```{r, fig.width=6, fig.align = 'center', fig.height=9}
csv.all.lc.mcro.df %>%
  # filter(yr == "2009" | yr == "2013") %>% 
  filter(str_detect(SPECIES_CODE, "^SA")) %>% 
  filter(SITE_TYPE == "WC") %>% 
  filter(SPECIES_CODE !="SAPE" & SPECIES_CODE !="SAWO" & SPECIES_CODE !="SAXX" & SPECIES_CODE !="SALUC" & SPECIES_CODE !="SABR" & SPECIES_CODE !="SAER" & SPECIES_CODE !="SALE" & SPECIES_CODE !="SALU") %>% 
  mutate(yr = as.factor(yr)) %>% 
  ggplot(aes(yr, CANOPY_DIA_CM_avg)) +
  geom_boxplot(color="black", fill = "ivory2") +
  geom_jitter(alpha=.1, color="blue") +
  facet_grid(SPECIES_CODE~SITE_TYPE, scales = "free_y") +
  theme_bw() +
  labs(title = "Core Elk Winter Range Canopy Width", y = "Canopy height (cm)")

```


```{r}
### core winter range
### by species

csv.all.lc.mcro.df %>%
  filter(FENCED == "N" | FENCED == "Y") %>% 
  filter(yr == "2008" | yr == "2013" | yr == "2018") %>%
  filter(str_detect(SPECIES_CODE, "^SA")) %>% 
  filter(SITE_TYPE == "WC") %>% 
  filter(SPECIES_CODE !="SAPE" & SPECIES_CODE !="SAWO" & SPECIES_CODE !="SAXX" & SPECIES_CODE !="SALUC" & SPECIES_CODE !="SABR" & SPECIES_CODE !="SAER" & SPECIES_CODE !="SALE" & SPECIES_CODE !="SALU" & SPECIES_CODE !="SALA"& SPECIES_CODE !="SABO") %>% 
  # mutate(yr = factor(yr)) %>%
  group_by(SPECIES_CODE,yr) %>% 
  mutate(med.canopydiam = median(CANOPY_DIA_CM_avg)) %>%
  mutate(ptile = ntile(CANOPY_DIA_CM_avg,n = 100)) %>%
  ungroup() %>% 
  # mutate(q3.canopydiam = quatmedian(CANOPY_DIA_CM_avg))
  ggplot(aes(FENCED, CANOPY_DIA_CM_avg)) +
  # geom_point(aes(y = CANOPY_DIA_CM_avg, color = FENCED)) +
  geom_boxplot() +
  geom_jitter(aes(y = CANOPY_DIA_CM_avg, color = FENCED), alpha = .5) +
  # geom_point(aes(y = med.canopydiam),color = "black", shape = 3, size = 5) +
  # geom_smooth(aes(x = )) +
  facet_grid(SPECIES_CODE~yr, scales = "free_y") +
  theme_bw() +
  labs(title = "Core Elk Winter Range Canopy Width", x = "Fenced", y = "Canopy height (cm)") 
  # labs(title = "Core Elk Winter Range Canopy Width", subtitle = "The black '+' indicates median value for group", x = "Fenced", y = "Canopy height (cm)")

```

```{r, eval = FALSE}

# The medians aren;t right. they seem to just be for the species/yr, not spp yr fenced
csv.all.lc.mcro.df %>%
  filter(FENCED == "N" | FENCED == "Y") %>% 
  filter(yr == "2008" | yr == "2013" | yr == "2018") %>%
  filter(str_detect(SPECIES_CODE, "^SA")) %>% 
  filter(SITE_TYPE == "WC") %>% 
  filter(SPECIES_CODE !="SAPE" & SPECIES_CODE !="SAWO" & SPECIES_CODE !="SAXX" & SPECIES_CODE !="SALUC" & SPECIES_CODE !="SABR" & SPECIES_CODE !="SAER" & SPECIES_CODE !="SALE" & SPECIES_CODE !="SALU" & SPECIES_CODE !="SALA"& SPECIES_CODE !="SABO") %>% 
  # mutate(yr = factor(yr)) %>%
  group_by(SPECIES_CODE,yr) %>% 
  mutate(med.canopydiam = median(CANOPY_DIA_CM_avg)) %>%
  mutate(ptile = ntile(CANOPY_DIA_CM_avg,n = 100)) %>%
  ungroup() %>% 
  # mutate(q3.canopydiam = quatmedian(CANOPY_DIA_CM_avg))
  ggplot(aes(FENCED, CANOPY_DIA_CM_avg)) +
  # geom_point(aes(y = CANOPY_DIA_CM_avg, color = FENCED)) +
  # geom_jitter(aes(y = CANOPY_DIA_CM_avg, color = FENCED)) +
  geom_point(aes(y = med.canopydiam),color = "black", shape = 3, size = 5) +
  # geom_smooth(aes(x = )) +
  facet_grid(SPECIES_CODE~yr, scales = "free_y") +
  theme_bw() +
  labs(title = "Core Elk Winter Range Canopy Width", subtitle = "The black '+' indicates median value for group", x = "Fenced", y = "Canopy height (cm)")


```


```{r}

```


#### Count of Observations by Species  

```{r}

csv.all.lc.mcro.df %>% 
  group_by(SPECIES_CODE) %>%
  tally() %>% 
  arrange(desc(n)) %>% 
  datatable(rownames = FALSE, caption = "Count of observations by shrub species.")

```


----

```{r,eval=FALSE}

# scrap
# line int
# csv.lineInt <- tibble(files = fs::dir_ls("data/EVMP_data/csv",glob = "*Line Intercept.csv"))

c.line <- fs::dir_ls("data/EVMP_data/csv",glob = "*Line Intercept.csv")


## read them all in and combines them
c.line.dat <- map_df(c.line,read_csv)

## many duplicates...
c.line.dat <- distinct(c.line.dat)

View(c.line.dat)
## compare this to just the longest record, Same?

Willow_Cumulative_Data_Baseline_Through_2018_2013_Line_Intercept <- read_csv("data/EVMP_data/csv/Willow_Cumulative_Data_Baseline_Through_2018-2013 Line Intercept.csv")
View(Willow_Cumulative_Data_Baseline_Through_2018_2013_Line_Intercept)

Willow_Cumulative_Data_Baseline_Through_2018_2008_09_Line_Intercept_Baseline <- read_csv("data/EVMP_data/csv/Willow_Cumulative_Data_Baseline_Through_2018-2008-09 Line Intercept Baseline.csv")
View(Willow_Cumulative_Data_Baseline_Through_2018_2008_09_Line_Intercept_Baseline)

```


### Aspen 

### Baseline 2013-2018

```{r}



#  data/EVMP_20181010/TenYearReview/Aspen_Data_Baseline_through_2018.xlsx

```


Tally of Live Aspen Stems per Plot >2.5 m in Height (DBH=diameter at breast height [1.4 m])		

Tally of Live Aspen Stems per Plot <2.5 m in Height				


Tally of Dead Aspen Stems per Plot >2.5 m in Height (DBH=diameter at breast height [1.4 m])

Cleaned data to make readable as csv

Site Type: AC=core, ANC=non-core, AK=Kawuneeche Valley


Rewrite the SAS program used to create figs. 3,4,5, and 7 of Zeigenfuss and Johnson (2015)--Distribution of aspen tree (height greater than 2.5 meters) stem diameters in monitoring sites. 

**Steps:** 
1. Read in data from a file with tallies of live aspen stems by dbh size class  
2. Read in a file with information for each aspen monitoring site  
3. Merge these two files, remove saplings 
4. Reclass trees into groups of small (2-10 cm dbh), medium (10-20 cm dbh) and large (20+ dbh) trees.


**See: **  

>aspen sapling table 4.sas  
>aspen sapling table 5.sas  



## Upland

**Data import** 

```{r, eval=TRUE}

uli <- readxl::excel_sheets("data/EVMP_data/TenYearReview/Upland_Line_Intercept_2007_2013_2018.xlsx")
# uli

b2007 <- readxl::read_excel("data/EVMP_data/TenYearReview/Upland_Line_Intercept_2007_2013_2018.xlsx",sheet = 2) %>% 
  mutate(yr = 2007)

b2013 <- readxl::read_excel("data/EVMP_data/TenYearReview/Upland_Line_Intercept_2007_2013_2018.xlsx",sheet = 3) %>% 
  mutate(yr = 2013)


b2018 <- readxl::read_excel("data/EVMP_data/TenYearReview/Upland_Line_Intercept_2007_2013_2018.xlsx",sheet = 4) %>% 
  mutate(yr = 2018) %>% 
  mutate(SHRUB_HEIGHT_CM = as.character(SHRUB_HEIGHT_CM))

# combine 07 and 13
baseline <- bind_rows(b2007,b2013) 

## bring in the 2018
baseline <- baseline %>% 
  bind_rows(., b2018)

# View(baseline)

# janitor::excel_numeric_to_date()

######### DEAL WITH NA #############
na_strings <- c("NA", "N A", "N / A", "N/A", "N/ A", "Not Available", "NOt available")

baseline <- baseline %>%
  naniar::replace_with_na_all(condition = ~.x %in% na_strings) %>%
  mutate(DATE = as.numeric(DATE)) 

# baseline %>%
#   excel_numeric_to_date(DATE, date_system = "modern")

```



```{r, eval=TRUE}

# Examine the file
baseline <- baseline %>% 
  filter(!is.na(UTM_E_NAD83))

baseline %>% 
  visdat::vis_dat() +
  labs(title = "Upland Vegetation -- Missing Values")
# + 
# coord_flip()


```

```{r, eval=FALSE}
bl.sel <- baseline %>%
  select(
  ELEVATION_M,
  starts_with("UTM"),
  DATE,
  SITE_ID,
  SITE_NUMBER,
  SITE_TYPE,
  SHRUB_SPECIES,
  SHRUB_HEIGHT_CM,
  yr
  ) 

####

bl.sel %>% 
  na.omit() 

```


### Willow Offtake


```{r, eval=FALSE}

# data/EVMP_20181010/TenYearReview/Willow_Cumulative_Data_Baseline_Through_2018.xlsx
wo <- readxl::excel_sheets("data/EVMP_data/TenYearReview/Willow_Cumulative_Data_Baseline_Through_2018.xlsx")
wo

path <- ("data/EVMP_data/TenYearReview/Willow_Cumulative_Data_Baseline_Through_2018.xlsx")


#### Read in the worksheets and create list of df
# each tab is a df in the list object
wo.d <- path %>% 
  excel_sheets() %>% 
  set_names() %>% 
  map(read_excel, path = path) # 

## this just got ALL of the tabs. Will want to subset the list to get the "like" types (e.g., rowbind columns structured the same way)
# wo.d %>% names()
#  [1] "KEY"                             "2008 Site Info"                 
#  [3] "2008-09 Macroplot Baseline"      "2008-09 Line Intercept Baseline"
#  [5] "2013 Site Info"                  "2013 Macroplot Inventory"       
#  [7] "2013 Line Intercept"             "2015 Site Info"                 
#  [9] "2015 Macroplot Inventory"        "2015 Line Intercept"            
# [11] "2016 Site Info"                  "2016 Macroplot Inventory"       
# [13] "2016 Line Intercept"             "2017 Site Info"                 
# [15] "2017 Macroplot Inventory"        "2017 Line Intercept"            
# [17] "2018 Site Info"                  "2018 Macroplot Inventory"       
# [19] "2018 Line Intercept"  


###### Get the names of the macroplot tabs as vector with datapasta
wo.d %>% 
  names() %>% 
  as.tibble() %>% 
  filter(str_detect(value, 'Macroplot')) # copy from clipboard and paste as vector

### Extract out just the macroplot tabs
mp.list <- purrr::map(c("z2008-09 Macroplot Baseline",
  "z2013 Macroplot Inventory",
  "z2015 Macroplot Inventory",
  "z2016 Macroplot Inventory",
  "z2017 Macroplot Inventory",
  "z2018 Macroplot Inventory"),
  ~ wo.d[.]) 

# get the names of df. Note use of the 'at_depth' argument to dial into the second level of the list
df.names <- mp.list %>% 
  at_depth(2, names) %>% 
  at_depth(2, tibble)

# df.names %>% 
#   at_depth(2,walk(.,View)) # this sort of works, but b/c of the nested lists, not useful

###### UNLIST!!!!! #####
new.pp <- unlist(df.names,recursive=FALSE)

# walk(new.pp,View) # this works! Opens a View portal for each list item 
# walk(new.pp,print) # prints each list item to console
# the takehome is there are different number of columns in each tab!
# can't combine

df.names %>% 
  at_depth(2,map_df(.,rbind))



##################
# purrr::map(c(#"2008-09 Macroplot Baseline",
#   "2013 Macroplot Inventory",
#   "2015 Macroplot Inventory",
#   "2016 Macroplot Inventory",
#   "2017 Macroplot Inventory",
#   "2018 Macroplot Inventory"),
#   ~ wo.d[.]) 



```



```{r, eval=FALSE}
# Create a cache of workbook tabs as CSV files
## cache csv. This creates a csv cache of each tab in the workbook. 

read_then_csv <- function(sheet, path) {
  pathbase <- path %>%
    basename() %>%
    tools::file_path_sans_ext()
  path %>%
    read_excel(sheet = sheet) %>% 
    write_csv(paste0(pathbase, "-", sheet, ".csv"))
}

path %>%
  excel_sheets() %>%
  set_names() %>% 
  map(read_then_csv, path = path)

map_df(.x = mp.list,.f = bind_rows)

mp.list2 <- mp.list %>% 
  map_if(is.numeric, as.character) 

bind_rows(mp.list, .id = "id")


za <- path %>%
  excel_sheets() %>%
  set_names() %>% 
  map_df(~ read_excel(path = path, sheet = .x), .id = "sheet")

path %>%
  excel_sheets() %>%
  set_names() %>% 
  map_df(~ read_excel(path = path, sheet = .x, range = "A2:F15"), .id = "sheet")

######
name.lineInt <- wo.d 
# %>% 
  # names() %>% 
  # as.tibble() %>% 
  # filter(str_detect(value, 'Line'))

wo.d %>%
  names() %>%
  as.tibble() %>%
  filter(str_detect(value, 'Site')) 
######

### Extract out just the line intercept
bl.list <- purrr::map(c("2008-09 Line Intercept Baseline",
  "2013 Line Intercept",
  "2015 Line Intercept",
  "2016 Line Intercept",
  "2017 Line Intercept",
  "2018 Line Intercept"),
  ~ name.lineInt[.]) 


# #### Example: extract subset
# library(purrr)
# library(magrittr)
#> 
#> Attaching package: 'magrittr'
#> The following object is masked from 'package:purrr':
#> 
# #>     set_names
# l <- list(a = "foo", b = "bar", c = "baz")
# 
# purrr::map(c("a", "b"), ~ l[.]) %>% unlist()
# ####


# library(readxl)    
# read_excel_allsheets <- function(filename) {
#     sheets <- readxl::excel_sheets(filename)
#     x <-    lapply(sheets, function(X) readxl::read_excel(filename, sheet = X))
#     names(x) <- sheets
#     x
# }
# 
# mysheets <- read_excel_allsheets("data/EVMP_20181010/TenYearReview/Willow_Cumulative_Data_Baseline_Through_2018.xlsx")


b2007 <- readxl::read_excel("data/EVMP_20181010/TenYearReview/Upland_Line_Intercept_2007_2013_2018.xlsx",sheet = 2) %>% 
  mutate(yr = 2007)

b2013 <- readxl::read_excel("data/EVMP_20181010/TenYearReview/Upland_Line_Intercept_2007_2013_2018.xlsx",sheet = 3) %>% 
  mutate(yr = 2013)


b2018 <- readxl::read_excel("data/EVMP_20181010/TenYearReview/Upland_Line_Intercept_2007_2013_2018.xlsx",sheet = 4) %>% 
  mutate(yr = 2018) %>% 
  mutate(SHRUB_HEIGHT_CM = as.character(SHRUB_HEIGHT_CM))

# combine 07 and 13
baseline <- bind_rows(b2007,b2013) 

## bring in the 2018
baseline <- baseline %>% 
  bind_rows(., b2018)

# View(baseline)


```


## Aspen Baseline 2013-2018


```{r}



```


## Willow Offtake 2009-2018

Rewrite the SAS program used to analyze willow height data as found in table 9 of Zeigenfuss and Johnson (2015)--Least squares means of average and maximum willow height and percent willow cover on burned sites compared to unburned sites using the macroplot method at EVMP willow monitoring sites in Rocky Mountain National Park, Colorado. 

**Steps:** 

1. Read in data from a file containing the baseline data from willow macroplots  
2. Calculate canopy area for each plot and assigns the baseline year (2008) to these data 
3. Sort data down to willow and non-willow species groups and calculates mean for the variables "average height" and "maximum ht" for each group.

**See: **  

>willow shrub cover macro table 8.sas  
>willow shrub height table 8.sas  
>willow shrub cover macro table 9.txt    
>willow shrub height table 9.txt  






# Discussion

Targets from Ziegenfuss and Johnson 2015:

1.Progressive increase in aspen regeneration above the baseline level of 13 percent to at least 45 percent of winter range stands (presence of stems less than 2 cm dbh reaching 1.5–2.5 m tall).

# References  

Johnson, T. L., L. C. Zeigenfuss, N. Thompson, and J. A. Mack. 2016. The role of science through a century of elk and habitat management at Rocky Mountain National Park. Park Science 32(2):70–72

U.S. Department of the Interior, 2007, Elk and vegetation management plan, Rocky Mountain National Park, Colorado: Washington D.C., National Park Service, unpaged, accessed online May 6, 2013 at http://www.nps.gov/romo/parkmgmt/elkveg_mgmt_plan_feis.htm.

U.S. Department of the Interior, 2008, Record of decision, Final environmental impact statement, Elk and vegetation management plan, Rocky Mountain National Park, Colorado: Washington D.C., National Park Service, 21 p., accessed online May 6, 2013 at www.nps.gov/romo/parkmgmt/upload/rod_evmp_signed_2-15-08.pdf.

Zeigenfuss, L., Johnson, T., and Wiebe, Z., 2011, Monitoring plan for vegetation responses to elk management in Rocky Mountain National Park: U.S. Geological Survey Open-File Report 2011–1013, 85 p.

Zeigenfuss, L.C., and T.L. Johnson, 2015, Monitoring of vegetation response to elk population and habitat management in Rocky Mountain National Park, 2008–14: U.S. Geological Survey Open-File Report 2015–1216, 44 p., http://dx.doi.org/10.3133/ofr20151216.




# Appendix 1. Data notes from E. Ertl

The following are notes from E. Ertl recorded in an describing EVMP vegetation data collection, as recorded in 2018.  

#### Aspen

* Plots lost: AC41 (plot was washed away in the 2013 flood)

* Plots added: AC68 to replace AC41

* Plots that had been treated with fuels management work that has not been noted before: ANC5, ANC7, ANC8, ANC19 (I think?) these areas were thinned of most large trees opening up the canopy substantially and the area was also pile burned; none of the plots appeared to be directly in the pile burn scars but a few came very close; these treatments could alter data in the future (working on getting a GIS layer for this)

* Formatted 2015 – 2018 data. 2015-2017 data only consisted of burn plot sampling; no burn plot data collected in 2014

#### Upland


* Plots lost: UC09 (this plot was most likely lost in the 2013 flood), UC14 & UC24 (plots were lost to waterline construction that occurred from 2015-2018)

* Plots added: UC37, UC38, UC39 to replace the three plots that were lost

* Plots have been treated by prescribed fire in the past; Prescribed fire occurred from 9/17 – 10/2 of 2008; First round of data collected for upland sites occurred in 2007 (working on getting recent GIS layers to account for any other treatments)

* Prescribed burning is planned for this coming October 2018 as well, which will potentially burn several upland plots in the Beaver Meadows area

* Formatted 2018 shrub data

#### Willow

* Plots lost: WK03; this plot hasn’t been found since 2012 and we looked several times in 2018

* Plots added: WK09 to replace WK03 (updated measurement schedule in the protocol), WK10 added late season after talking with Linda Z. – she suggested there be 4 fenced plots in the KV to make the data collected from this area more robust. We weren’t aware of this when we installed WK09, so there will be nine total west side plots (4 fenced and 5 unfenced).

* Removed the microplot stem counts from the macroplot sampling in the protocol per Linda Z. early summer

* Formatted 2015 – 2018 cumulative willow data
	2015-2017 data only consisted of burn plot sampling; there is no burn data for 2014
	In 2015 it appears they were only measuring willow in the macroplots, not all shrubs like they should have been.

* Fixed unit and rounding issues in data.	In 2016 the crew measured additional burned sites that are not on the burn survey list (WC32, WC34, WC78, WC84, and WC85). For some plots they only measured willow instead of measuring all shrubs. Fixed unit and rounding issues in data.

* There is only west side data for 2016 and 2017; Nick B. said they weren’t aware that west side plots were supposed to be measured every year back in 2014/2015. Burn survey and west side data are currently combined by year measured

* Formatted 2015 – 2018 offtake data (2014 was already added and analyzed in the 2013 review)
	2015 offtake notes: Crew didn’t sample WC9, WC78, WC79 (plots are in fences) and sampled extra plots that are not on the protocol list for offtake including WC34, WC35, WC52, WC54, WC56, WK6, WK7, and WK8 (none of these are in fences)

* 2016 offtake notes: Crew didn’t sample WC79 (fenced), WC85 (fenced), WK3 (lost), WNC30 (couldn’t find plot) and sampled extra plots that are not on the protocol list for offtake including WC34, WC35, WC37 (fenced), WC50 (fenced), WC57, WC69, WC70, WC71, WC76 (fenced), WC81, WC82, WC83, WC86 (fenced)

*	2017 offtake notes: Crew didn’t sample WC76 (fenced), WC85 (fenced), WNC30 (couldn’t find plot), WK3 (lost), WK6 (river probably too high to access) and no extra plots were sampled

*	2018 offtake notes: Crew didn’t sample WC33 (removed 2014), WC76 (fenced), WC77 (fenced), WK3 (lost and removed from list in 2018, replaced with WK9 at end of season), WK6 (river too high to access plot)  
* There were discrepancies between the protocol and the willow master database on what sites to sample for offtake (added by C. Piper). Linda and I updated this schedule in the protocol for future years because the old schedule included plots that were no longer there and plots that have since been fenced.

* Burn Surveys 2015-2019 – spoke with Linda Z. and she doesn’t think these need to be measured again in 2019 unless the data is showing something interesting.

* Willow stake restoration sites – have these been cross referenced with willow monitoring sites? Were willow stakes planted in some plots? I did find notes that there were willow stakes being measured in WC76 over the years, which would need to be analyzed separately I’m assuming.

#### Other notes

* Kept all of Linda’s original data for the last 5-year review under EVMP’s “analysis” folder

* Created new (2018) versions of data for 10-year review analysis but did not delete out any data from previous years where plots were lost this year; also kept old components in the data (i.e. willow shoot measurements, microplot stem counts)

* All formatted data for 2018 can be found under EVMPVegetationAnalysis10 Year Review

* Blank datasheets have been updated for 2018

* Protocols are currently being updated for 2018 and master databases have been updated for 2018. 

* Added a “Fuels Treatment Post Establishment” and “Treatment Year” column that could be queried by type (i.e. prescribed fire, mechanical treatments, etc.) 

* Created new shapefiles for all veg plots; trying to find shapefiles for treatment areas in the park and will put them in the EVMP_Veg_Data_2018 geodatabase
	Located under EVMPVegetationGISEVMP_Veg_Data_2018.gdb OR ShapefilesMaster_Veg_Sites_Shp2018

* Created new veg maps. Located under EVMPVegetationLogisticsMapsEVMP vegetation plot maps2018 Veg Site MapsPlot Maps

* Wild Basin Willow Data – I created a folder with all of the data collected at Wild Basin this fall. It is located under EVMPVegetationAnnual RecordsFY18Wild Basin – Willow Data
* Uploaded all 4 iPads with new electronic datasheets for willow and upland, photo points and plot diagrams from 2018, willow ID keys, updated protocol from 2018, and new vegetation site maps.

-----


```{r, eval=FALSE, echo=FALSE}

######## bin
### mapview example
library(leaflet)
## default position is topleft next to zoom control

img <- "https://www.r-project.org/logo/Rlogo.svg"
leaflet() %>% addTiles() %>% addLogo(img, url = "https://www.r-project.org/logo/")

## with local image
library(png)

img <- system.file("img", "Rlogo.png", package="png")
leaflet() %>% addTiles() %>% addLogo(img, src = "local", alpha = 0.3)

## dancing banana gif :-)
m <- mapview(breweries91)

addLogo(m, "https://jeroenooms.github.io/images/banana.gif",
        position = "bottomleft",
        offset.x = 5,
        offset.y = 40,
        width = 100,
        height = 100)

addLogo(m, img,
        position = "bottomleft",
        offset.x = 5,
        offset.y = 40,
        width = 100,
        height = 100)

#### slide view
library(jpeg)
library(raster)

web_img2000 <- "http://cdn.newsapi.com.au/image/v1/68565a36c0fccb1bc43c09d96e8fb029"

jpg2000 <- readJPEG(readBin(web_img2000, "raw", 1e6))

# Convert imagedata to raster
rst_blue2000 <- raster(jpg2000[, , 1])
rst_green2000 <- raster(jpg2000[, , 2])
rst_red2000 <- raster(jpg2000[, , 3])

img2000 <- brick(rst_red2000, rst_green2000, rst_blue2000)

web_img2013 <- "http://cdn.newsapi.com.au/image/v1/5707499d769db4b8ec76e8df61933f2a"

jpg2013 <- readJPEG(readBin(web_img2013, "raw", 1e6))

# Convert imagedata to raster
rst_blue2013 <- raster(jpg2013[, , 1])
rst_green2013 <- raster(jpg2013[, , 2])
rst_red2013 <- raster(jpg2013[, , 3])

img2013 <- brick(rst_red2013, rst_green2013, rst_blue2013)

slideView(img2000, img2013, label1 = "before", label2 = "after")
# f'in awesome...


```






