---
title: "EVMP Exploratory Analysis"
author: "Ed Gage"
date: ""
output: 
  html_document: 
    theme: paper
---


```{r setup, include=FALSE}
library(knitr)
opts_chunk$set(echo = FALSE, warning = FALSE)
opts_knit$set(root.dir=normalizePath('../')) # this is required if Rmd is nested below the project directory
opts_chunk$set(fig.path = "../output/figures/") # corrected path and added dev. Needed to specify a subdirectory for figs

# see discussion here: https://stackoverflow.com/questions/24585254/working-with-knitr-using-subdirectories

```


**Updated: `r format(Sys.time(), '%Y %B %d')`**

# Introduction

This document provides a basic exploration of EVMP files provided by RMNP in October 10, 2018.

Analyses aim to characterize basic data structure, clean and reorganize as needed for plotting and modeling. Identify potential issues such as:

* Inconsistently named/typed factors    
* Missing values
* Data values outside of expected range or showing unusual patterns


```{r,echo=FALSE}
# library(here)
# here()
# install.packages("bindrcpp")
suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(fs))
suppressPackageStartupMessages(library(sf))
# library(raster)
suppressPackageStartupMessages(library(janitor))
suppressPackageStartupMessages(library(readxl))
# library(glue)
suppressPackageStartupMessages(library(mapview))
# library(ggmap)
# library(ggrepel)
suppressPackageStartupMessages(library(viridis))
# library(ggExtra)
suppressPackageStartupMessages(library(ggstance))
suppressPackageStartupMessages(library(readxl))
suppressPackageStartupMessages(library(DT))
# library(kableExtra)
suppressPackageStartupMessages(library(lubridate))
suppressPackageStartupMessages(library(skimr)) ## some useful functions
suppressPackageStartupMessages(library(dataMaid))
# library(ggmap)

```

# Data Exploration and Wrangling

## Import and overview   

__List of files provided by RMNP (10/10/2018):__

```{r}
# list of files 
# fs::dir_ls(recursive = TRUE) 

file.listing <- dir_info(recursive = TRUE) %>%
  filter(type == "file", permissions == "u+r", size > "10KB") %>%
  arrange(desc(size)) %>%
  select(path, size, modification_time)

datatable(file.listing, rownames = FALSE, caption = "List of files provided by RMNP 2018-10-10")

```


```{r}

# xls_example <- readxl_example("datasets.xls")
# excel_sheets(xls_example)


# willow.off <- read_xlsx("data/EVMP_data/provisional_data_20180920/Willow Offtake Data 2009-2018.xlsx")
# read_excel(willow.off, sheet = "chickwts")
# excel_sheets(willow.off)
# 
# asp.bl <- read_excel("data/EVMP_data/provisional_data_20180920/Aspen_Baseline_2013_2018_5_Year_Msmts_Including_Burn_Data.xlsx") 
# 
# excel_sheets(asp.bl)

```


### Aspen Baseline 2013-2018

**Data import**  

Tally of Live Aspen Stems per Plot >2.5 m in Height (DBH=diameter at breast height [1.4 m])		

Tally of Live Aspen Stems per Plot <2.5 m in Height				


Tally of Dead Aspen Stems per Plot >2.5 m in Height (DBH=diameter at breast height [1.4 m])

Cleaned data to make readable as csv

Site Type: AC=core, ANC=non-core, AK=Kawuneechee Valley

```{r}

fs::dir_ls("data/EVMP_20181010/TenYearReview")

#  data/EVMP_20181010/TenYearReview/Aspen_Data_Baseline_through_2018.xlsx


```



#### Quality checks

**Missing data**  


### Willow Offtake 2009-2018 

**Data import** 
```{r}


# data/EVMP_20181010/TenYearReview/Willow_Cumulative_Data_Baseline_Through_2018.xlsx
wo <- readxl::excel_sheets("data/EVMP_20181010/TenYearReview/Willow_Cumulative_Data_Baseline_Through_2018.xlsx")
wo

path <- ("data/EVMP_20181010/TenYearReview/Willow_Cumulative_Data_Baseline_Through_2018.xlsx")


#### Read in the worksheets and create list of df
# each tab is a df in the list object
wo.d <- path %>% 
  excel_sheets() %>% 
  set_names() %>% 
  map(read_excel, path = path) # 

## this just got ALL of the tabs. Will want to subset the list to get the "like" types (e.g., rowbind columns structured the same way)
# wo.d %>% names()
#  [1] "KEY"                             "2008 Site Info"                 
#  [3] "2008-09 Macroplot Baseline"      "2008-09 Line Intercept Baseline"
#  [5] "2013 Site Info"                  "2013 Macroplot Inventory"       
#  [7] "2013 Line Intercept"             "2015 Site Info"                 
#  [9] "2015 Macroplot Inventory"        "2015 Line Intercept"            
# [11] "2016 Site Info"                  "2016 Macroplot Inventory"       
# [13] "2016 Line Intercept"             "2017 Site Info"                 
# [15] "2017 Macroplot Inventory"        "2017 Line Intercept"            
# [17] "2018 Site Info"                  "2018 Macroplot Inventory"       
# [19] "2018 Line Intercept"  



###### Get the names of the macroplot tabs as vector with datapasta
wo.d %>% 
  names() %>% 
  as.tibble() %>% 
  filter(str_detect(value, 'Macroplot')) # copy from clipboard and paste as vector

### Extract out just the macroplot tabs
mp.list <- purrr::map(c(#"z2008-09 Macroplot Baseline",
  "z2013 Macroplot Inventory",
  "z2015 Macroplot Inventory",
  "z2016 Macroplot Inventory",
  "z2017 Macroplot Inventory",
  "z2018 Macroplot Inventory"),
  ~ wo.d[.]) 


purrr::map(c(#"2008-09 Macroplot Baseline",
  "2013 Macroplot Inventory",
  "2015 Macroplot Inventory",
  "2016 Macroplot Inventory",
  "2017 Macroplot Inventory",
  "2018 Macroplot Inventory"),
  ~ wo.d[.]) 


## cache csv
read_then_csv <- function(sheet, path) {
  pathbase <- path %>%
    basename() %>%
    tools::file_path_sans_ext()
  path %>%
    read_excel(sheet = sheet) %>% 
    write_csv(paste0(pathbase, "-", sheet, ".csv"))
}

path %>%
  excel_sheets() %>%
  set_names() %>% 
  map(read_then_csv, path = path)




map_df(.x = mp.list,.f = bind_rows)

mp.list2 <- mp.list %>% 
  # map(as.character)
  map_if(is.numeric, as.character) 


bind_rows(mp.list, .id = "id")


za <- path %>%
  excel_sheets() %>%
  set_names() %>% 
  map_df(~ read_excel(path = path, sheet = .x), .id = "sheet")

path %>%
  excel_sheets() %>%
  set_names() %>% 
  map_df(~ read_excel(path = path, sheet = .x, range = "A2:F15"), .id = "sheet")

# # #  fail
# ss <- data.table::rbindlist(mp.list, use.names=TRUE, fill=TRUE) %>% as.data.frame()


######

######
name.lineInt <- wo.d 
# %>% 
  # names() %>% 
  # as.tibble() %>% 
  # filter(str_detect(value, 'Line'))

wo.d %>%
  names() %>%
  as.tibble() %>%
  filter(str_detect(value, 'Site')) 
######

### Extract out just the line intercept
bl.list <- purrr::map(c("2008-09 Line Intercept Baseline",
  "2013 Line Intercept",
  "2015 Line Intercept",
  "2016 Line Intercept",
  "2017 Line Intercept",
  "2018 Line Intercept"),
  ~ name.lineInt[.]) 


# #### Example: extract subset
# library(purrr)
# library(magrittr)
#> 
#> Attaching package: 'magrittr'
#> The following object is masked from 'package:purrr':
#> 
# #>     set_names
# l <- list(a = "foo", b = "bar", c = "baz")
# 
# purrr::map(c("a", "b"), ~ l[.]) %>% unlist()
# ####




## not working. unpack
# data_xlsx_df <- map_df(set_names(files), function(file) {
#   file %>% 
#     excel_sheets() %>% 
#     set_names() %>% 
#     map_df(
#       ~ read_xlsx(path = file, sheet = .x1),
#       .id = "sheet")
# }, .id = "file")


# library(readxl)    
# read_excel_allsheets <- function(filename) {
#     sheets <- readxl::excel_sheets(filename)
#     x <-    lapply(sheets, function(X) readxl::read_excel(filename, sheet = X))
#     names(x) <- sheets
#     x
# }
# 
# mysheets <- read_excel_allsheets("data/EVMP_20181010/TenYearReview/Willow_Cumulative_Data_Baseline_Through_2018.xlsx")


b2007 <- readxl::read_excel("data/EVMP_20181010/TenYearReview/Upland_Line_Intercept_2007_2013_2018.xlsx",sheet = 2) %>% 
  mutate(yr = 2007)

b2013 <- readxl::read_excel("data/EVMP_20181010/TenYearReview/Upland_Line_Intercept_2007_2013_2018.xlsx",sheet = 3) %>% 
  mutate(yr = 2013)


b2018 <- readxl::read_excel("data/EVMP_20181010/TenYearReview/Upland_Line_Intercept_2007_2013_2018.xlsx",sheet = 4) %>% 
  mutate(yr = 2018) %>% 
  mutate(SHRUB_HEIGHT_CM = as.character(SHRUB_HEIGHT_CM))

# combine 07 and 13
baseline <- bind_rows(b2007,b2013) 

## bring in the 2018
baseline <- baseline %>% 
  bind_rows(., b2018)

# View(baseline)

```


#### Quality checks

**Missing data**  


### Willow Cumulative 2013-2018

**Data import** 
```{r}

# data/EVMP_20181010/TenYearReview/Willow_Cumulative_Data_Baseline_Through_2018.xlsx

```


#### Quality checks

**Missing data**


### Upland Line Intercept 2007-2018

SITE_TYPE (UC=Upland Core, UNC=Upland Noncore)

ANIMAL_SIGN_TYPE (T=Track, S=Scat, P=Present, B=Burrows, D=Plant Damage, BR=Browse)

ANIMAL_SIGN_SPECIES (E=Elk, D=Deer, M=Moose, GS=Ground Squirrels, C=Tent Caterpillars, BHS=Big Horn Sheep, R=Raptor)

SHRUB_SPECIES (Individual shrubs measured along 30 m transect line)



**Data import** 
```{r}

uli <- readxl::excel_sheets("data/EVMP_20181010/TenYearReview/Upland_Line_Intercept_2007_2013_2018.xlsx")
uli

b2007 <- readxl::read_excel("data/EVMP_20181010/TenYearReview/Upland_Line_Intercept_2007_2013_2018.xlsx",sheet = 2) %>% 
  mutate(yr = 2007)

b2013 <- readxl::read_excel("data/EVMP_20181010/TenYearReview/Upland_Line_Intercept_2007_2013_2018.xlsx",sheet = 3) %>% 
  mutate(yr = 2013)


b2018 <- readxl::read_excel("data/EVMP_20181010/TenYearReview/Upland_Line_Intercept_2007_2013_2018.xlsx",sheet = 4) %>% 
  mutate(yr = 2018) %>% 
  mutate(SHRUB_HEIGHT_CM = as.character(SHRUB_HEIGHT_CM))

# combine 07 and 13
baseline <- bind_rows(b2007,b2013) 

## bring in the 2018
baseline <- baseline %>% 
  bind_rows(., b2018)

# View(baseline)

# janitor::excel_numeric_to_date()

######### DEAL WITH NA #############

na_strings <- c("NA", "N A", "N / A", "N/A", "N/ A", "Not Available", "NOt available")

baseline %>%
  naniar::replace_with_na_all(condition = ~.x %in% na_strings) %>%
  mutate(DATE = as.numeric(DATE)) 
# %>% 
#   excel_numeric_to_date(DATE, date_system = "modern")  



```

The following plot illustrates missing data amd data type 
```{r}

# Examine the file
baseline %>% 
  visdat::vis_dat() + 
  coord_flip()


```

```{r}
bl.sel <- baseline %>%
  select(
  ELEVATION_M,
  starts_with("UTM"),
  DATE,
  SITE_ID,
  SITE_NUMBER,
  SITE_TYPE,
  SHRUB_SPECIES,
  SHRUB_HEIGHT_CM,
  yr
  ) 



####

bl.sel %>% 
  na.omit() 

```



#### Quality checks

**Missing data**

# Translation of Past Analyses from SAS 


### Aspen Baseline 2013-2018


```{r}



```


### Willow Offtake 2009-2018

Rewrite the SAS program used to analyze willow height data as found in table 9 of Zeigenfuss and Johnson (2015)--Least squares means of average and maximum willow height and percent willow cover on burned sites compared to unburned sites using the macroplot method at EVMP willow monitoring sites in Rocky Mountain National Park, Colorado. 

**Steps:** 

1. Read in data from a file contaning the baseline data from willow macroplots  
2. Calculate canopy area for each plot and assigns the baseline year (2008) to these data 
3. Sort data down to willow and non-willow species groups and calculates mean for the variables "average height" and "maximum ht" for each group.

**See: **  

>willow shrub cover macro table 8.sas  
>willow shrub height table 8.sas  
>willow shrub cover macro table 9.txt    
>willow shrub height table 9.txt  


### Willow Cumulative 2013-2018


### Upland Line Intercept 2007-2018

Rewrite the SAS program used to create figs. 3,4,5, and 7 of Zeigenfuss and Johnson (2015)--Distribution of aspen tree (height greater than 2.5 meters) stem diameters in monitoring sites. 

**Steps:** 
1. Read in data from a file with tallies of live aspen stems by dbh size class  
2. Read in a file with information for each aspen monitoring site  
3. Merge these two files, remove saplings 
4. Reclass trees into groups of small (2-10 cm dbh), medium (10-20 cm dbh) and large (20+ dbh) trees.


**See: **  

>aspen sapling table 4.sas  
>aspen sapling table 5.sas  


## Recreation of Figures from Past Publications  

**Key publications:**  

_Zeigenfuss, L. C., and T. L. Johnson. 2015. Monitoring of Vegetation Response to Elk Population and Habitat Management in Rocky Mountain National Park, 2008â€“14. Report 2015-1216, U.S. Geological Survey, Reston, VA._
[Link](http://pubs.er.usgs.gov/publication/ofr20151216)

# Plots as in LZ 2015






