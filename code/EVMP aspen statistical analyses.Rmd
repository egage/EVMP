---
title: "EVMP Aspen Statistical Analyses"
author: ""
date: ""
output: 
  html_document: 
    theme: journal
    toc: yes
    toc_depth: 4
---

```{r setup, include=FALSE}
library(knitr)
opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, fig.align = 'center')
opts_knit$set(root.dir=normalizePath('../')) # this is required if Rmd is nested below the project directory
opts_chunk$set(fig.path = "../output/figures/") # corrected path and added dev. Needed to specify a subdirectory for figs
```

```{r}
set.seed(123)
```


```{r,echo=FALSE}
# library(here)
# here()
# install.packages("bindrcpp")
suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(fs))
suppressPackageStartupMessages(library(sf))
# library(raster)
suppressPackageStartupMessages(library(janitor))
suppressPackageStartupMessages(library(readxl))
# library(glue)
suppressPackageStartupMessages(library(mapview))
# library(ggmap)
# library(ggrepel)
suppressPackageStartupMessages(library(viridis))
# library(ggExtra)
suppressPackageStartupMessages(library(ggstance))
suppressPackageStartupMessages(library(readxl))
suppressPackageStartupMessages(library(DT))
# library(kableExtra)
suppressPackageStartupMessages(library(lubridate))
suppressPackageStartupMessages(library(skimr)) 
suppressPackageStartupMessages(library(dataMaid))
# library(ggmap)
library(lubridate)
library(mapview)
library(vtree)

library(emmeans)
## bayesian
library(rstanarm)
library(bayestestR)
# library(easystats)

library(rstatix) # rstatix: Pipe-Friendly Framework for Basic Statistical Tests

# devtools::install_github("dkahle/ggmap")
library(ggmap)
library(gt)
library(ggrepel)

# install.packages("devtools")
# devtools::install_github("easystats/easystats")

## vroom https://vroom.r-lib.org/articles/vroom.html
```

## Functions
### Table functions
```{r, eval = TRUE}
## function to describe model out
fun.desc.post1 <- function(model){
  describe_posterior(
  model,
  effects = "fixed",
  component = "all",
  ci_method = "hdi",
  test = c("p_direction", "p_significance"),
  centrality = "all"
) %>% 
    as_tibble() %>% 
    DT::datatable(caption = "Posterior description")
}


## gt

fun.desc.post1.gt <- function(model){
  describe_posterior(
  model,
  effects = "fixed",
  component = "all",
  ci_method = "hdi",
  test = c("rope"),
  #rope_range(c(-0.1,0.1)),
  rope_range("default"),
  centrality = "median"
) %>% 
    as_tibble() %>% 
    gt() %>% 
    tab_header(title = "Posterior description") %>% 
    fmt_number(
    columns = 2:12,
    decimals = 1,
    suffixing = TRUE
  )
}

# fun.desc.post1.gt(stmod_ht2)

```
#### Plotting functions
```{r}
fun.contrast.plot <- function(df){
  df %>% 
  ggplot(aes(x = contrast)) +
  geom_linerange(aes(ymin = lower.HPD, ymax = upper.HPD), color = "lightblue", size = 2) +
  geom_point(aes(y = estimate), size = 2.5) +
  theme_minimal() +
  labs(caption = "Point estimate displayed: median 
HPD interval probability: 0.95", x = "Estimate", y = "Estimate") +
  coord_flip()
}

```

```{r}
## ppcheck.plot
ppc.plot <- function(model){
  pp_check(model) +
  labs(x = "Value", y = "Density") +
  theme_minimal()
}

```


## Aspen Data
```{r}
## read in data

# Aspen ht
ht_perc1 <- read_csv("./output/exported_data/asp_ht_perc1_20200309.csv")
ht_perc1 %>% 
  glimpse()

ht_perc1 %>% 
  visdat::vis_dat()

```

```{r}
## filter out in-between years
ht_perc1 <- ht_perc1 %>%
  filter(timeClass %in% c("BL","2013", "2018")) 

### factor relevel
ht_perc1 <- ht_perc1 %>% 
  mutate(timeClass = as.factor(timeClass)) %>% 
  mutate(timeClass = fct_relevel(timeClass, "BL", "2013", "2018")) %>% 
  mutate(RANGE_TYPE = as.factor(RANGE_TYPE)) %>% 
  mutate(RANGE_TYPE = fct_relevel(RANGE_TYPE, "core winter range","non-core winter range","Kawuneeche Valley"))   

```

```{r}
ht_perc1 <- ht_perc1 %>% 
  clean_names()

## set factor levels for burned and fenced
ht_perc1 <- ht_perc1 %>%
  mutate(fenced.long = case_when(fenced == "N" ~ "Unfenced",
                                 fenced == "Y" ~ "Fenced",
                                 TRUE ~ fenced)) %>% 
  mutate(burned = case_when(burned == "Not burned" ~ "Unburned",
                            TRUE ~ burned)) %>%
  mutate(fenced.long = as_factor(fenced.long)) %>%
  mutate(burned = as_factor(burned))

ht_perc1 %>% 
  distinct(site_type)
  
asp.ac <- ht_perc1 %>% 
  filter(site_type == "AC") 

# non core
asp.anc <- ht_perc1 %>% 
  filter(site_type == "ANC")

asp.akv <- ht_perc1 %>% 
  filter(site_type == "AK")

```




### Traditional AOV

```{r}
# ht_perc1 <- as.data.frame(ht_perc1)

aov_model_asp_htperc <- aov(stemDen.ha ~ RANGE_TYPE*timeClass + Error(SITE_ID/(RANGE_TYPE*timeClass)), data = ht_perc1)


#### example
# stress.aov <- with(myData.mean,
#                    aov(stress ~ music * image +
#                        Error(PID / (music * image)))
# )
# Error() term we threw in there? Pretty simple: what we’re saying is that we want to look at how stress changes as a function of the music and image that participants were shown. (Thus the stress ~ music * image) The asterisk specifies that we want to look at the interaction between the two IVs as well. But since this was a repeated measures design, we need to specify an error term that accounts for natural variation from participant to participant. We do this with the Error() function: specifically, we are saying that we want to control for that between-plot variation over all of our within-subjects variables.


```


### Bayesian Analyses

A Bayesian analysis returns a posterior distribution for each parameter (or effect). To minimally describe these distributions. Report the following:

*a point-estimate of centrality  
*information characterizing the estimation uncertainty (the dispersion).  
* Additionally, one can also report indices of effect existence and/or significance.

Suggest reporting the median as an index of centrality, as it is more robust compared to the mean or the MAP estimate. However, in case of severly skewed posterior distributions, the MAP estimate could be a good alternative

The 89% Credible Interval (CI) appears as a reasonable range to characterize the uncertainty related to the estimation, being more stable than higher thresholds (such as 90% and 95%). We also recommend computing the CI based on the HDI rather than quantiles, favouring probable, - over central - values.


```{r, eval=FALSE}
# Identifiers - rstanarm does not require identifiers to be sequential. It is good practice for all cluster and unit identifiers, as well as categorical variables be stored as factors. This applies to using lme4 as much as it does to rstanarm. One can check the structure of the variables by using the str() function.
```




## AC - Aspen stem count

#### main factors only

```{r}
## adding a tiny number to conform with gamma
asp.ac <- asp.ac %>%
  mutate(stem_den_ha = stem_den_ha +0.0000001)
  
## run with gamma
# stmod_ht1 <- stan_glmer(stem_den_ha ~ time_class + fenced + (1 | site_id), data = asp.ac,
#                        family=Gamma(link="log"),
#                       iter = 10000,
#                       )
# prior_summary(stmod_ht1)
# pp_check(stmod_ht1)
# not useful


## poisson
stmod_stally1 <- stan_glmer(stem_tally ~ time_class + fenced + (1 | site_id), data = asp.ac,
                       family=poisson,
                      iter = 10000,
                      seed = 1234
                      )

prior_summary(stmod_stally1)
pp_check(stmod_stally1)
```

#### main factors + interactions

```{r}
## run with gamma
stmod_stally2 <- stan_glmer(stem_tally ~ time_class * fenced + (1 | site_id), data = asp.ac,
                       family= poisson,
                      iter = 10000,
                      seed = 1234
                      )

summary(stmod_stally2)
prior_summary(stmod_stally2)

pp.stally2.wc <- pp_check(stmod_stally2)
pp.stally2.wc +
  labs(x = "Value", y = "Density") +
  theme_minimal()

```

```{r, eval = FALSE}
# install.packages("shinystan")
library("shinystan")
## shiny eval
launch_shinystan(stmod_stally2)

```


#### Model comparison

Compares model with and without interactions for AC plots
```{r, eval = FALSE}
## model comparison
loo1 <- loo(stmod_stally1,
            k_threshold = 0.7) # Found 3 observation(s) with a pareto_k > 0.7. We recommend calling 'loo' again with argument 'k_threshold = 0.7' in order to calculate the ELPD without the assumption that these observations are negligible. This will refit the model 3 times to compute the ELPDs for the problematic observations directly.

loo2 <- loo(stmod_stally2,
            k_threshold = 0.7) 
comp <- loo_compare(loo2, loo1)

## create table of comparisons
modcomp_ac <- print(comp, simplify = TRUE, digits = 2)

modcomp_ac %>% 
  gt()
# citation(package = "loo")



# show more details with simplify=FALSE
# (will be the same for all models in this artificial example)
print(comp, simplify = FALSE, digits = 3)
```

```{r, eval = FALSE}
## report
# report::report(stmod_stally2)
```

```{r, eval = FALSE}
# note the function in the next chunk is good
describe_posterior(
  stmod_ht1,
  effects = "all",
  component = "all",
  test = c("p_direction", "p_significance"),
  centrality = "all"
)
# Posterior: point estimates
centrality <- point_estimate(stmod_ht1)  # Get indices of centrality
centrality
```

### model checks

```{r}
# Compare the model with default weak priors and the one with the null
#pp_check(stmod_ht2)

ppc.plot(stmod_stally2)
# ggsave("./output/figures_exported/ac_stemtally_ppc1.png", dpi = 300, width = 4.75, height = 3.75)
# pp_check(stmod_ht2)
# pp_check(stmod_ht1_noPrior)


```


### Model posterior parameters to table
```{r}
fun.desc.post1.gt(stmod_stally2) %>% 
  gt::gtsave(filename = "./output/tables/ac_stemcnt_stmod2_posteriors.rtf")


```

get posteriors

```{r}
posteriors.ac.stcnt <- insight::get_parameters(stmod_stally2)

posteriors.ac.stcnt %>% 
  glimpse()

# tidy the posteriors
posteriors.ac.stcnt.tidy <- posteriors.ac.stcnt %>%
  # names()
  pivot_longer(cols = starts_with("time"), names_to = "variable", values_to = "values")

```

```{r}
library(ggridges)

posteriors.ac.stcnt.tidy %>% 
  ggplot() +
  ggridges::geom_density_ridges(aes(x = values, y = variable))

posteriors.ac.stcnt.tidy %>% 
  ggplot() +
  geom_density(aes(fill = variable, x = values, color = variable), alpha = .12) +
  theme_minimal()

```

#### PD - AC
```{r}
pd.ac <- p_direction(stmod_stally2)
p.in.rope.ac <- rope(stmod_stally2, ci=1)

pd.tab.ac <- p.in.rope.ac %>% 
  gt() %>%
  tab_header(title = "Percent in ROPE") %>% 
  fmt_number(
    columns = 5,
    decimals = 1,
    suffixing = TRUE
  ) 
pd.tab.ac %>% 
# pd.tab.wcc %>% 
  gt::gtsave(filename = "./output/tables/ac_stemcnt_percent_in_ROPE.rtf")

# Visualise the pd
ac.stmcnt.pd <- plot(pd.ac)
ac.stmcnt.pd +
  theme_minimal() +
  labs(caption = "Aspen stem count, core winter range")
# ggsave("./output/figures_exported/pd_ac_stemcnt.png", dpi = 300, width = 6.75, height =3.75)
```


### Contrasts - WC time class

EMMs for later factor levels are subtracted from those for earlier levels; if you want the comparisons to go in the other direction, use pairs(pigs.emm.s, reverse = TRUE).
```{r}
# library(emmeans)
ac.emm.stcnt <- emmeans(stmod_stally2, ~ time_class)

ac.pairs.timeClass <- pairs(ac.emm.stcnt, reverse = TRUE)

# pairs.timeClass <- pairs(emmeans(stmod_ht2, ~ time_class)) # more compact way to do above

# ex: contrast(warp.emm, "trt.vs.ctrl", ref = "M")

gg.emm.ac.stcnt <- plot(ac.pairs.timeClass) +
  theme_minimal() +
  labs(subtitle = "Point estimate displayed: median 
HPD interval probability: 0.95", x = "Estimate", y = "Contrast", caption = "Core Winter Range, Aspen Stem Count")

gg.emm.ac.stcnt
# ggsave("./output/figures_exported/gg_emm_ac_stcnt.png", width = 4.5, height = 3.55, dpi=300)


# pairs.timeClass.exp %>% 
#   ggplot(aes(x = contrast)) +
#   geom_point(aes(y = estimate)) +
#   geom_linerange(aes(ymin = lower.HPD, ymax = upper.HPD)) +
#   theme_minimal() +
#   labs(title = "Point estimate displayed: median 
# HPD interval probability: 0.95")

fun.contrast.plot(ac.pairs.timeClass)


```

```{r}
# library(emmeans)
ac.emm.stcnt.fen <- emmeans(stmod_stally2, ~ fenced)

ac.pairs.fenced <- pairs(ac.emm.stcnt.fen, reverse = TRUE)

gg.emm.ac.stcnt.fenced <- plot(ac.pairs.fenced) +
  theme_minimal() +
  labs(subtitle = "Point estimate displayed: median 
HPD interval probability: 0.95", x = "Estimate", y = "Contrast", caption = "Core Winter Range, Aspen Stem Count")

gg.emm.ac.stcnt.fenced

```


```{r, eval = FALSE}

ac.emm.stcnt.fenxTC <- emmeans(stmod_stally2, ~time_class * fenced)

pairs.timeClassxfenced.ac <- pairs(ac.emm.stcnt.fenxTC, by = "fenced", reverse = TRUE) # simple effects for color

plot(pairs.timeClassxfenced.ac) +
  theme_minimal() +
  # labs(x = "Median estimate", y = "", caption = "pairs.timeClassxRange") +
  labs(subtitle = "Point estimate displayed: median 
HPD interval probability: 0.95", x = "Median estimate", y = "Contrast", caption = "Core Winter Range, Aspen stem count")

# ggsave("./output/figures_exported/gg_emm_ac_ht_TC_Fenced.png", width = 4.5, height = 3.55, dpi=300)
```

## AC - Burned

```{r}
ht_perc1_summary <- ht_perc1 %>%
  group_by(time_class, range_type, burned, fenced.long) %>% 
  summarytools::descr(stats = "fivenum") %>% 
  summarytools::tb()

ht_perc1 %>% 
  filter(range_type == "core winter range") %>% 
  filter(time_class == "BL" | time_class == "2013" | time_class == "2018") %>%
  group_by(time_class, range_type, burned, fenced.long) %>% 
  # summarytools::descr(stats = "fivenum") %>% 
  summarytools::descr() %>%
  summarytools::tb() %>% 
  datatable(filter = "top")

```

```{r}
ht_perc1 %>% 
  filter(range_type == "core winter range") %>% 
  filter(time_class == "BL" | time_class == "2013" | time_class == "2018") %>% 
  ggplot(aes(burned, log(stem_tally))) +
  geom_boxplot(aes(fill = time_class)) +
  facet_wrap(~fenced.long) +
  ylim(0, 5)
  

ht_perc1 %>% 
  filter(range_type == "core winter range") %>% 
  filter(time_class == "BL" | time_class == "2013" | time_class == "2018") %>%
  ggplot(aes(stem_tally)) +
  # geom_density(aes(color = time_class)) +
  geom_histogram(aes(fill = time_class),position = "dodge") +
  facet_wrap(burned ~ fenced.long) +
  xlim(0, 5)


```


```{r}
### STAN model
stmod_ac_burned_stally1 <- stan_glmer(stem_tally ~ fenced.long * time_class * burned + (1 | site_id), data = asp.ac,
                       family=poisson,
                      iter = 10000,
                      seed = 1234
                      )

prior_summary(stmod_ac_burned_stally1)
pp_check(stmod_ac_burned_stally1)

```

```{r}
pd.ac.burned <- p_direction(stmod_ac_burned_stally1)
p.in.rope.ac.burned <- rope(stmod_ac_burned_stally1, ci=1)

pd.tab.ac.burned <- p.in.rope.ac.burned %>% 
  gt() %>%
  tab_header(title = "Percent in ROPE") %>% 
  fmt_number(
    columns = 5,
    decimals = 1,
    suffixing = TRUE
  ) 
pd.tab.ac.burned %>% 
# pd.tab.wcc %>% 
  gt::gtsave(filename = "./output/tables/ac_stemcnt_burned_TC_percent_in_ROPE.rtf")

# Visualise the pd
ac.stmcnt.pd.burned <- plot(pd.ac.burned)
ac.stmcnt.pd.burned +
  theme_minimal() +
  labs(caption = "Aspen stem count, core winter range")

# ggsave("./output/figures_exported/pd_ac_stemcnt_burned_fenced.png", dpi = 300, width = 6.75, height =5.75)
# ggsave("./output/figures_exported/pd_ac_stemcnt_burned_fenced.pdf", width = 6.75, height =5.75)
```

```{r}
## contrasts
# library(emmeans)

ac.burned.emmgrid <- emmeans::ref_grid(stmod_ac_burned_stally1)

ac.emm.stcnt.burned <- emmeans(stmod_ac_burned_stally1, ~ burned)

plot(ac.emm.stcnt.burned)

ac.pairs.burned <- pairs(ac.emm.stcnt.burned, reverse = TRUE)

ac.burned.emmgrid.pairs <- 
  pairs(ac.burned.emmgrid, reverse = TRUE)

# type - response
plot(ac.burned.emmgrid, by = "burned",type = "response")
# type - linear predictor
plot(ac.burned.emmgrid, by = "burned", type = "linear.predictor") + 
  theme_minimal()


# plot(ac.burned.emmgrid, by = "fenced.long")

gg.emm.ac.stcnt.burned <- plot(ac.burned.emmgrid, by = "time_class") +
  theme_minimal() +
labs(subtitle = "Point estimate displayed: median 
HPD interval probability: 0.95", x = "Estimate", y = "Contrast", caption = "Core Winter Range, Aspen Stem Count - Burned")

gg.emm.ac.stcnt.burned
# ggsave("./output/figures_exported/gg_emm_ac_stcnt_burned.png", width = 4.5, height = 5.55, dpi=300)
# ggsave("./output/figures_exported/gg_emm_ac_stcnt_burned.pdf", width = 4.5, height = 5.55)

```


----

## ANC - Aspen stem count

### main factors + interactions

```{r}
stmod_anc_stally1 <- stan_glmer(stem_tally ~ time_class * fenced + (1 | site_id), data = asp.ac,
                       family=poisson,
                      iter = 10000,
                      seed = 1234
                      )

prior_summary(stmod_anc_stally1)
pp_check(stmod_anc_stally1)

```




```{r}
# get posteriors
posteriors.anc.stmcnt <- insight::get_parameters(stmod_anc_stally1)

posteriors.anc.stmcnt %>% 
  glimpse()


```

#### PP check plot
```{r}
ppc.plot(stmod_anc_stally1)
# ggsave("./output/figures_exported/anc_stmcnt.png", dpi = 300, width = 4.75, height = 3.75)
```


#### Model posterior parameters to table
```{r, eval = FALSE}

## View
fun.desc.post1.gt(stmod_anc_stally1)


## save
fun.desc.post1.gt(stmod_anc_stally1) %>% 
  gt::gtsave(filename = "./output/tables/stmod_anc_stally1.rtf")


```


```{r, eval = FALSE}
# install.packages("shinystan")
library("shinystan")
## shiny eval
launch_shinystan(stmod_anc_stally1)
```

#### PD - ANC
```{r}
pd.anc <- p_direction(stmod_anc_stally1)
p.in.rope.anc <- rope(stmod_anc_stally1, ci=1)

pd.tab.anc <- p.in.rope.anc %>% 
  gt() %>%
  tab_header(title = "Percent in ROPE") %>% 
  fmt_number(
    columns = 5,
    decimals = 1,
    suffixing = TRUE
  ) 
pd.tab.anc
# pd.tab.wnc %>% 
#   gt::gtsave(filename = "./output/tables/wnc_wh_percent_in_ROPE.rtf")

# Visualise the pd
anc.stmcnt.pd <- plot(pd.anc)
anc.stmcnt.pd +
  theme_minimal() +
  labs(caption = "Aspe stem count, non-core winter range")
# ggsave("./output/figures_exported/pd_anc_stemcntb.png", dpi = 300, width = 6.75, height =3.75)
```

#### Contrasts - time class
```{r}
# library(emmeans)
anc.emm <- emmeans(stmod_anc_stally1, ~ time_class,)

anc.pairs.timeClass <- pairs(anc.emm)

gg.emm.anc.stmcnt <- plot(anc.pairs.timeClass) +
  theme_minimal() +
  labs(subtitle = "Point estimate displayed: median 
HPD interval probability: 0.95", x = "Estimate", y = "Contrast", caption = "Non-core Winter Range, Aspen stem counts")

gg.emm.anc.stmcnt
# ggsave("./output/figures_exported/gg_emm_anc_stmcnt_TConly.png", width = 4.5, height = 3.55, dpi=300)

```

#### Contrasts - Fenced * time class
```{r}
# library(emmeans)
anc.emm.tcxf <- emmeans(stmod_anc_stally1, ~ time_class*fenced)

anc.pairs.tcxf <- pairs(anc.emm.tcxf, by = "fenced", reverse = TRUE)

anc.pairs.tcxf %>% 
  gt()

gg.emm.anc.stmcnt.tcxf <- plot(anc.pairs.tcxf) +
  theme_minimal() +
  labs(subtitle = "Point estimate displayed: median 
HPD interval probability: 0.95", x = "Estimate", y = "Contrast", caption = "Non-core Winter Range, Aspen stem counts")

gg.emm.anc.stmcnt.tcxf
# ggsave("./output/figures_exported/gg_emm_anc_stmcnt_tcxf.png", width = 4.5, height = 3.55, dpi=300)

```


## AK - Aspen stem count

### Model spec
```{r}
asp.akv %>% visdat::vis_dat()


kv.stmod_stmcnt1 <- stan_glmer(stem_tally ~ time_class + (1 | site_id), data = asp.akv,
                       family=poisson,
                      iter = 10000,
                      seed = 1234,
                      control = list(adapt_delta = 0.99))

# There were 2 divergent transitions after warmup. Increasing adapt_delta to 0.99
# see: https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup

# pairs(kv.stmod_stmcnt1)

prior_summary(kv.stmod_stmcnt1)
# pp_check(kv.stmod_stmcnt1)
```

#### PP check plot
```{r}
ppc.plot(kv.stmod_stmcnt1)
ggsave("./output/figures_exported/ak_stemct_ppc1.png", dpi = 300, width = 4.75, height = 3.75)
```


#### Model posterior parameters to table
```{r, eval = FALSE}

## View
fun.desc.post1.gt(kv.stmod_stmcnt1)


## save
fun.desc.post1.gt(kv.stmod_stmcnt1) %>% 
  gt::gtsave(filename = "./output/tables/AK_kv.stmod_stmcnt1_posteriors.rtf")


```

#### PD - KV
```{r}
pdkv <- p_direction(kv.stmod_stmcnt1)
p.in.rope.kv <- rope(kv.stmod_stmcnt1, ci=1)

pd.tab.kv <- p.in.rope.kv %>% 
  gt() %>%
  tab_header(title = "Percent in ROPE") %>% 
  fmt_number(
    columns = 5,
    decimals = 1,
    suffixing = TRUE
  ) 
pd.tab.kv
pd.tab.kv %>%
  gt::gtsave(filename = "./output/tables/wnc_wh_percent_in_ROPE.rtf")

# Visualise the pd
kv.stmcnt.pd <- plot(pdkv)
kv.stmcnt.pd +
  theme_minimal() +
  labs(caption = "Willow height, KV")
ggsave("./output/figures_exported/pd_kv_stmcnt.png", dpi = 300, width = 6.75, height =3.75)

```

#### Contrasts - KV tc
```{r}
# library(emmeans)
kv.emm <- emmeans(kv.stmod_stmcnt1, ~ time_class)

kv.pairs.fenced <- pairs(kv.emm, reverse = TRUE)

gg.emm.kv.stmcnt <- plot(kv.pairs.fenced) +
  theme_minimal() +
  labs(subtitle = "Point estimate displayed: median 
HPD interval probability: 0.95", x = "Estimate", y = "Contrast", caption = "KV, aspen stem count")

gg.emm.kv.stmcnt
ggsave("./output/figures_exported/gg_emm_AK_stmcnt.png", width = 4.5, height = 3.55, dpi=300)

```




# working above

# Early iterations below
Fit model - STAN_LMER

```{r}
stan_model <- stan_lmer(stemDen.ha ~ timeClass*RANGE_TYPE + (1 | SITE_ID), data = ht_perc1,
                        prior = cauchy(0,c(0.707,0.707,0.5)), 
                        prior_intercept = student_t(3,0,10),                                     prior_aux = exponential(.1),
                        prior_covariance = decov(1,1,1,1))

prior_summary(stan_model)


```

```{r, eval=FALSE}
## guess at some more informative priors
stan_model_b <- stan_glmer(stemDen.ha ~ timeClass*RANGE_TYPE + (1 | SITE_ID), 
                           data = ht_perc1,
                           family = binomial(link = "logit"),
                           prior = cauchy(0,c(0.707,0.707,0.5)),
                      prior_intercept = student_t(0,0,1),                                     prior_aux = exponential(.1),
                        prior_covariance = decov(1,1,1,1))


stan_glm(Days ~ Sex/(Age + Eth*Lrn), data = MASS::quine, seed = 123,
         family = neg_binomial_2, QR = TRUE, algorithm = "optimizing")
```


Describe posterior

```{r}
describe_posterior(
  stan_model,
  effects = "all",
  component = "all",
  test = c("p_direction", "p_significance"),
  centrality = "all"
)

```

```{r, eval = FALSE}
desc.post1 <- function(model){
  describe_posterior(
  model,
  effects = "all",
  component = "all",
  test = c("p_direction", "p_significance"),
  centrality = "all"
) %>% 
    as_tibble() %>% 
    DT::datatable(caption = "Posterior description")
}

desc.post1(stan_model)
```

Posterior: point estimates

```{r}
centrality <- point_estimate(stan_model)  # Get indices of centrality
centrality
```


```{r}
# null prior
stan_model2 <- stan_lmer(stemDen.ha ~ timeClass*RANGE_TYPE + (1 | SITE_ID), data = ht_perc1,
                        prior = NULL)
```

```{r}
pp_check(stan_model)
pp_check(stan_model2)
pp_check(stan_model_b)

```



get posteriors

```{r}
posteriors <- insight::get_parameters(stan_model)
posteriors2 <- insight::get_parameters(stan_model2)

# head(posteriors) %>% 
#   datatable()# Show the first 6 rows
# glimpse(posteriors)

posteriors.t1 <- posteriors %>%
  # names()
  pivot_longer(cols = starts_with("time"), names_to = "variable", values_to = "values")


library(ggridges)

posteriors.t1 %>% 
  ggplot() +
  ggridges::geom_density_ridges(aes(x = values, y = variable))

posteriors.t1 %>% 
  ggplot() +
  geom_density(aes(fill = variable, x = values, color = variable), alpha = .12) +
  theme_minimal()


library(emmeans)
pairs.timeClass <- pairs(emmeans(stan_model, ~ timeClass))
pairs.timeClass
plot(pairs.timeClass) +
  labs(title = "Aspen density")



```

```{r}
pairs.range_type <- pairs(emmeans(stan_model, ~ RANGE_TYPE))
pairs.range_type
plot(pairs.range_type) +
  theme_minimal() +
  labs(x = "Median estimate", y = "", caption = "pairs.range_type")
```


```{r}

pairs.timeClassxRange <- emmeans(stan_model, ~timeClass * RANGE_TYPE)
pairs(pairs.timeClassxRange, by = "timeClass") # simple effects for color
plot(pairs.timeClassxRange) +
  theme_minimal() +
  labs(x = "Median estimate", y = "", caption = "pairs.timeClassxRange") 


```

Compute Confidence/Credible/Compatibility Intervals (CI) or Support Intervals (SI) for Bayesian and frequentist models. 

bayestestR provides two methods to compute credible intervals, the Highest Density Interval (HDI) (hdi()) and the Equal-tailed Interval (ETI) (eti()). These methods can also be changed via the method argument of the ci() function.

```{r}
# Compute HDI and ETI
ci_hdi <- ci(posteriors, method = "HDI")
ci_eti <- ci(posteriors, method = "ETI")

# Plot the distribution and add the limits of the two CIs
# posteriors %>% 
#   select(timeClass2:RANGE_TYPE2) %>% 
#   estimate_density(extend=TRUE) %>% 
#   ggplot(aes(x=x, y=y)) +
#   geom_area(fill="orange") +
#   theme_classic() +
#   # HDI in blue
#   geom_vline(xintercept=ci_hdi$CI_low, color="royalblue", size=3) +
#   geom_vline(xintercept=ci_hdi$CI_high, color="royalblue", size=3) +
#   # Quantile in red
#   geom_vline(xintercept=ci_eti$CI_low, color="red", size=1) +
#   geom_vline(xintercept=ci_eti$CI_high, color="red", size=1)

```




Using the fantastic emmeans package, we can explore and extract marginal effects and estimates from our fitted model. For example, we can estimate the main effect for color

We can also estimate (based on posterior draws) the difference between the two simple effects for color between the levels of shape:

```{r}

pairs.timeClassxRange <- emmeans(stan_model, ~timeClass * RANGE_TYPE)
pairs(pairs.timeClassxRange, by = "timeClass") # simple effects for color
plot(pairs.timeClassxRange) +
  theme_minimal() +
  labs(x = "Median estimate", y = "", caption = "pairs.timeClassxRange") 


```


```{r}
# c_color_shape_interaction <- contrast(stan_model, interaction = c("pairwise","pairwise"))
# c_color_shape_interaction
```


#### stan_aov

```{r}

# my_prior <- normal(location = c(-10, 0), scale = c(5, 2), autoscale = FALSE)
# stan_glm(y ~ x1 + x2, data = dat, prior = my_prior)

stav <- stan_aov(stemDen.ha ~ RANGE_TYPE*timeClass, data = ht_perc1, prior = NULL)


```



```{r}
# Using the fantastic emmeans package, we can explore and extract marginal effects and estimates from our fitted model. For example, we can estimate the main effect for color:
# 
library(emmeans)
pairs.timeClass <- pairs(emmeans(stav, ~ timeClass))
pairs.timeClass

pairs.range_type <- pairs(emmeans(stav, ~ RANGE_TYPE))
pairs.range_type


plot(pairs.timeClass)
plot(pairs.range_type)


# We can also estimate (based on posterior draws) the difference between the two simple effects for color between the levels of shape:

em.timeClassxRange <- emmeans(stav, ~timeClass * RANGE_TYPE)
pairs(em.timeClassxRange, by = "timeClass") # simple effects for color
plot(em.timeClassxRange)

```

>EMMs for later factor levels are subtracted from those for earlier levels; if you want the comparisons to go in the other direction, use pairs(pigs.emm.s, reverse = TRUE). Also, in multi-factor situations, you may specify by factor(s) to perform the comparisons separately at the levels of those factors.


## Willow height - macroplot

### Read in and munge for modeling

```{r}
willow <- read_csv("./output/exported_data/willow_mcro.csv")

willow <- willow %>% 
  select(-c(pType, WILDERNESS, contains("UTM"))) 

willow.ht <- willow %>% 
  filter(!is.na(PLANT_HT_CM)) %>% 
  # distinct(yr)
  mutate(timeClass = case_when(yr == 2008 ~ "BL",
                              yr == 2009 ~ "BL", 
                              TRUE ~ as.character(yr))) 

willow.ht <- willow.ht %>% 
  filter(timeClass == "BL" | timeClass == "2013" | timeClass == "2018")

# willow.ht %>% distinct(timeClass)

```

### STAN model: willow height ~ timeClass * RANGE_TYPE

```{r}
willow.ht <- willow.ht %>% 
  mutate(timeClass = as.factor(timeClass)) %>% 
  mutate(timeClass = fct_relevel(timeClass, "BL", "2013", "2018"))
```


```{r}

# willow.ht %>% glimpse()
stan_mcroHt1 <- stan_lmer(PLANT_HT_CM ~ timeClass*RANGE_TYPE + (1 | SITE_ID), data = willow.ht,
                          iter = 3000,
                        prior = cauchy(0,c(0.707,0.707,0.5)), 
                        prior_intercept = student_t(3,0,10),                                     prior_aux = exponential(.1),
                        prior_covariance = decov(1,1,1,1))


```

#### Describe posterior

```{r}
# describe_posterior(
#   stan_mcroHt1,
#   effects = "all",
#   component = "all",
#   test = c("p_direction", "p_significance"),
#   centrality = "all"
# )

post1.fencedRT <- describe_posterior(
  stan_mcroHt1,
  effects = "all",
  ci = 0.9,
  ci_method = "hdi",
  component = "all",
  test = c("p_direction", "p_significance"),
  centrality = "all"
)

post1.fencedRT %>% 
  as_tibble() %>% 
  datatable()

```

Posterior: point estimates

```{r}
centrality.mcroHt1 <- point_estimate(stan_mcroHt1)  # Get indices of centrality

centrality.mcroHt1

```


### STAN model: fenced vs unfenced and range type

```{r}
##
stan_mcroHt1_fenced1 <- stan_lmer(PLANT_HT_CM ~ timeClass*RANGE_TYPE*FENCED + (1 | SITE_ID), data = willow.ht,
                        prior = cauchy(0,c(0.707,0.707,0.5)), 
                        prior_intercept = student_t(3,0,10),                                     prior_aux = exponential(.1),
                        prior_covariance = decov(1,1,1,1))


stan_mcroHt1_fenced1

```

```{r, eval = FALSE}

## shinystan
# install.packages("shinystan")
library("shinystan")
# launch_shinystan_demo()
# More info

## shiny eval
launch_shinystan(stan_mcroHt1_fenced1)

```


```{r}
pp_check(stan_mcroHt1_fenced1)
```


```{r}
# Compute indices
pd <- p_direction(stan_mcroHt1_fenced1)
percentage_in_rope <- rope(stan_mcroHt1_fenced1, ci=1)

# Visualise the pd
plot(pd)
```


% latex table generated in R 3.6.1 by xtable 1.8-4 package
% Fri Mar 13 12:05:39 2020
\begin{table}[ht]
\centering
\begin{tabular}{lrrrrrrr}
  \toprule
Parameter & Rhat & n\_eff & mean & sd & 2.5\% & 50\% & 97.5\% \\ 
  \midrule
mu & 1.0 & 1030 & 8.4 & 5.4 & -2.4 & 8.2 & 18.8 \\ 
  theta[1] & 1.0 & 1022 & 12.5 & 8.7 & -2.3 & 11.3 & 33.1 \\ 
   \bottomrule
\end{tabular}
\end{table}

```{r}



```


#### posterior datatable: fenced range type

```{r}
post1.fencedRT <- describe_posterior(
  stan_mcroHt1_fenced1,
  effects = "all",
  ci = 0.9,
  ci_method = "hdi",
  component = "all",
  test = c("p_direction", "p_significance"),
  centrality = "all"
)

post1.fencedRT %>% 
  as_tibble() %>% 
  datatable()

```

# func


### Scrap

#### Repeated measures

```{r, echo=FALSE, eval=FALSE}
# worked R bloggers example
# see: https://www.r-bloggers.com/two-way-anova-with-repeated-measures/

set.seed(5250)

myData <- data.frame(PID = rep(seq(from = 1,
                               to = 50, by = 1), 20),
                     stress = sample(x = 1:100,
                                     size = 1000,
                                     replace = TRUE),
                     image = sample(c("Happy", "Angry"),
                                    size = 1000,
                                    replace = TRUE),
                     music = sample(c("Disney", "Horror"),
                                    size = 1000,
                                    replace = TRUE)
)

myData <- within(myData, {
  PID   <- factor(PID)
  image <- factor(image)
  music <- factor(music)
})

myData <- myData[order(myData$PID), ]
head(myData)

PID stress image  music
  1     90 Happy Disney
  1     70 Angry Horror
  1     61 Angry Horror
  1     87 Happy Horror
  1     79 Happy Disney
  1     95 Happy Horror
So we see that we have one row per observation per participant. If your dataset is in wide form rather than long, I’d suggest checking out our article on converting between wide and long since everything from this point out assumes that your data look like what’s shown above!

Extracting Condition Means
Before we can run our ANOVA, we need to find the mean stress value for each participant for each combination of conditions. We’ll do that with:

myData.mean <- aggregate(myData$stress,
                      by = list(myData$PID, myData$music,
                              myData$image),
                      FUN = 'mean')

colnames(myData.mean) <- c("PID","music","image","stress")

myData.mean <- myData.mean[order(myData.mean$PID), ]
head(myData.mean)

PID  music   image   stress
  1 Disney   Angry 39.33333
  1 Horror   Angry 65.50000
  1 Disney   Happy 68.00000
  1 Horror   Happy 69.57143
  1 Disney Neutral 40.00000
  1 Horror Neutral 52.66667
So now we’ve gone from one row per participant per observation to one row per participant per condition. At this point we’re ready to actually construct our ANOVA!

Building the ANOVA
Now, our actual ANOVA is going to look something like this:

stress.aov <- with(myData.mean,
                   aov(stress ~ music * image +
                       Error(PID / (music * image)))
)
But what’s all that mean? What’s with that funky Error() term we threw in there? Pretty simple: what we’re saying is that we want to look at how stress changes as a function of the music and image that participants were shown. (Thus the stress ~ music * image) The asterisk specifies that we want to look at the interaction between the two IVs as well. But since this was a repeated measures design, we need to specify an error term that accounts for natural variation from participant to participant. (E.g., I might react a little differently to scary music than you do because I love zombie movies and you hate them!) We do this with the Error() function: specifically, we are saying that we want to control for that between-participant variation over all of our within-subjects variables.

Now that we’ve specified our model, we can go ahead and look at the results:

summary(stress.aov)

Error: PID
          Df Sum Sq Mean Sq F value Pr(>F)
Residuals 49   8344   170.3               

Error: PID:music
          Df Sum Sq Mean Sq F value Pr(>F)
music      1      1    0.78   0.003  0.954
Residuals 49  11524  235.19               

Error: PID:image
          Df Sum Sq Mean Sq F value Pr(>F)
image      1     61   61.11   0.296  0.589
Residuals 49  10127  206.66               

Error: PID:music:image
            Df Sum Sq Mean Sq F value Pr(>F)
music:image  1    564   563.8   2.626  0.112
Residuals   49  10520   214.7  
We see that there is no main effect of either music:

F(1, 49) = 0.003; p-value = 0.954
or image:

F(1, 49) = 0.296; p-value = 0.589
on participant stress. Likewise, we see that there is not a significant interaction effect between the two independent variables:

F(1, 49) = 2.626; p-value = 0.112
```


```{r}

```

